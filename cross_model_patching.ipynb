{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "014efce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.nn import CosineSimilarity\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LlamaForCausalLM, LlamaTokenizer\n",
    "from functools import partial\n",
    "from baukit import TraceDict\n",
    "from einops import rearrange, einsum\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly_utils import imshow, scatter\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from peft import PeftModel\n",
    "\n",
    "import pysvelte\n",
    "import analysis_utils\n",
    "from counterfactual_datasets.entity_tracking import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(10)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "068509e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loading...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Model Loading...\"</span>)                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 # path = \"AlekseyKorshuk/vicuna-7b\"</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>path = <span style=\"color: #808000; text-decoration-color: #808000\">\"/data/nikhil_prakash/llama_weights/7B\"</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 4 llama_tokenizer = AutoTokenizer.from_pretrained(path)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>llama_model = AutoModelForCausalLM.from_pretrained(path).to(device)                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 # base_model = \"decapoda-research/llama-7b-hf\"</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/transformers/models/auto/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">token</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ization_auto.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">622</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">619 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> tokenizer_class.from_pretrained(pretrained_model_name_or_path, *input   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">620 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">621 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Next, let's try to use the tokenizer_config file to get the tokenizer class.</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>622 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">623 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> tokenizer_config:                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">624 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span>] = tokenizer_config[<span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span>]                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">625 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>config_tokenizer_class = tokenizer_config.get(<span style=\"color: #808000; text-decoration-color: #808000\">\"tokenizer_class\"</span>)                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/transformers/models/auto/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">token</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ization_auto.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">466</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_tokenizer_config</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">463 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">tokenizer_config = get_tokenizer_config(\"tokenizer-test\")</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">464 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">```\"\"\"</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">465 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>commit_hash = kwargs.get(<span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>466 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>resolved_config_file = cached_file(                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">467 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>pretrained_model_name_or_path,                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">468 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>TOKENIZER_CONFIG_FILE,                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">469 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>cache_dir=cache_dir,                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hub.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">409</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cached_file</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 406 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>user_agent = http_user_agent(user_agent)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 407 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 408 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Load from URL or cache if already cached</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 409 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>resolved_file = hf_hub_download(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 410 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>path_or_repo_id,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 411 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>filename,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 412 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>subfolder=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(subfolder) == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> subfolder,                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/huggingface_hub/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_validat</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ors.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">110</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_fn</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">107 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>kwargs.items(),  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Kwargs values</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>):                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> arg_name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> [<span style=\"color: #808000; text-decoration-color: #808000\">\"repo_id\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"from_id\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"to_id\"</span>]:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>110 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>validate_repo_id(arg_value)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> arg_name == <span style=\"color: #808000; text-decoration-color: #808000\">\"token\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> arg_value <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>has_token = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/huggingface_hub/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_validat</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ors.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">158</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">validate_repo_id</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">155 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> HFValidationError(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Repo id must be a string, not {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>(repo_id)<span style=\"color: #808000; text-decoration-color: #808000\">}: '{</span>repo_   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">156 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">157 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> repo_id.count(<span style=\"color: #808000; text-decoration-color: #808000\">\"/\"</span>) &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>158 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> HFValidationError(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">160 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\" '{</span>repo_id<span style=\"color: #808000; text-decoration-color: #808000\">}'. Use `repo_type` argument if needed.\"</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">161 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">HFValidationError: </span>Repo id must be in the form <span style=\"color: #008000; text-decoration-color: #008000\">'repo_name'</span> or <span style=\"color: #008000; text-decoration-color: #008000\">'namespace/repo_name'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'/data/nikhil_prakash/llama_weights/7B'</span>. Use `repo_type` argument if needed.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m4\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 1 \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mModel Loading...\u001b[0m\u001b[33m\"\u001b[0m)                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 2 \u001b[0m\u001b[2m# path = \"AlekseyKorshuk/vicuna-7b\"\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0mpath = \u001b[33m\"\u001b[0m\u001b[33m/data/nikhil_prakash/llama_weights/7B\u001b[0m\u001b[33m\"\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 4 llama_tokenizer = AutoTokenizer.from_pretrained(path)                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0mllama_model = AutoModelForCausalLM.from_pretrained(path).to(device)                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m# base_model = \"decapoda-research/llama-7b-hf\"\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/transformers/models/auto/\u001b[0m\u001b[1;33mtoken\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mization_auto.py\u001b[0m:\u001b[94m622\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m619 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m tokenizer_class.from_pretrained(pretrained_model_name_or_path, *input   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m620 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m621 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m622 \u001b[2m│   │   \u001b[0mtokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m623 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m tokenizer_config:                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m624 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs[\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m] = tokenizer_config[\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m]                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m625 \u001b[0m\u001b[2m│   │   \u001b[0mconfig_tokenizer_class = tokenizer_config.get(\u001b[33m\"\u001b[0m\u001b[33mtokenizer_class\u001b[0m\u001b[33m\"\u001b[0m)                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/transformers/models/auto/\u001b[0m\u001b[1;33mtoken\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mization_auto.py\u001b[0m:\u001b[94m466\u001b[0m in \u001b[92mget_tokenizer_config\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m463 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33mtokenizer_config = get_tokenizer_config(\"tokenizer-test\")\u001b[0m                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m464 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m```\"\"\"\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m465 \u001b[0m\u001b[2m│   \u001b[0mcommit_hash = kwargs.get(\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mNone\u001b[0m)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m466 \u001b[2m│   \u001b[0mresolved_config_file = cached_file(                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m467 \u001b[0m\u001b[2m│   │   \u001b[0mpretrained_model_name_or_path,                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m468 \u001b[0m\u001b[2m│   │   \u001b[0mTOKENIZER_CONFIG_FILE,                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m469 \u001b[0m\u001b[2m│   │   \u001b[0mcache_dir=cache_dir,                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/transformers/utils/\u001b[0m\u001b[1;33mhub.py\u001b[0m:\u001b[94m409\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mcached_file\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 406 \u001b[0m\u001b[2m│   \u001b[0muser_agent = http_user_agent(user_agent)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 407 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 408 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Load from URL or cache if already cached\u001b[0m                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 409 \u001b[2m│   │   \u001b[0mresolved_file = hf_hub_download(                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 410 \u001b[0m\u001b[2m│   │   │   \u001b[0mpath_or_repo_id,                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 411 \u001b[0m\u001b[2m│   │   │   \u001b[0mfilename,                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 412 \u001b[0m\u001b[2m│   │   │   \u001b[0msubfolder=\u001b[94mNone\u001b[0m \u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(subfolder) == \u001b[94m0\u001b[0m \u001b[94melse\u001b[0m subfolder,                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validat\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mors.py\u001b[0m:\u001b[94m110\u001b[0m in \u001b[92m_inner_fn\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m107 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs.items(),  \u001b[2m# Kwargs values\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m108 \u001b[0m\u001b[2m│   │   \u001b[0m):                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m109 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m arg_name \u001b[95min\u001b[0m [\u001b[33m\"\u001b[0m\u001b[33mrepo_id\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mfrom_id\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mto_id\u001b[0m\u001b[33m\"\u001b[0m]:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m110 \u001b[2m│   │   │   │   \u001b[0mvalidate_repo_id(arg_value)                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melif\u001b[0m arg_name == \u001b[33m\"\u001b[0m\u001b[33mtoken\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mand\u001b[0m arg_value \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mhas_token = \u001b[94mTrue\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validat\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mors.py\u001b[0m:\u001b[94m158\u001b[0m in \u001b[92mvalidate_repo_id\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m155 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m HFValidationError(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mRepo id must be a string, not \u001b[0m\u001b[33m{\u001b[0m\u001b[96mtype\u001b[0m(repo_id)\u001b[33m}\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mrepo_   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m repo_id.count(\u001b[33m\"\u001b[0m\u001b[33m/\u001b[0m\u001b[33m\"\u001b[0m) > \u001b[94m1\u001b[0m:                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m158 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m HFValidationError(                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mRepo id must be in the form \u001b[0m\u001b[33m'\u001b[0m\u001b[33mrepo_name\u001b[0m\u001b[33m'\u001b[0m\u001b[33m or \u001b[0m\u001b[33m'\u001b[0m\u001b[33mnamespace/repo_name\u001b[0m\u001b[33m'\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\"\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mrepo_id\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m. Use `repo_type` argument if needed.\u001b[0m\u001b[33m\"\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mHFValidationError: \u001b[0mRepo id must be in the form \u001b[32m'repo_name'\u001b[0m or \u001b[32m'namespace/repo_name'\u001b[0m: \n",
       "\u001b[32m'/data/nikhil_prakash/llama_weights/7B'\u001b[0m. Use `repo_type` argument if needed.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Model Loading...\")\n",
    "# path = \"AlekseyKorshuk/vicuna-7b\"\n",
    "path = \"/data/nikhil_prakash/llama_weights/7B\"\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "llama_model = AutoModelForCausalLM.from_pretrained(path).to(device)\n",
    "\n",
    "# base_model = \"decapoda-research/llama-7b-hf\"\n",
    "# lora_weights = \"tiedong/goat-lora-7b\"\n",
    "\n",
    "# goat_model = LlamaForCausalLM.from_pretrained(\n",
    "#     base_model,\n",
    "#     load_in_8bit=False,\n",
    "#     torch_dtype=torch.float32,\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "# goat_model = PeftModel.from_pretrained(\n",
    "#     goat_model,\n",
    "#     lora_weights,\n",
    "#     torch_dtype=torch.float32,\n",
    "#     device_map={'': 0},\n",
    "# )\n",
    "\n",
    "llama_tokenizer.pad_token_id = llama_tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "767b0032",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"./box_datasets/no_instructions/alternative/Random/5/train.jsonl\"\n",
    "object_file = \"./box_datasets/objects_with_bnc_frequency.csv\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bcc0eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 600\n"
     ]
    }
   ],
   "source": [
    "raw_data = entity_tracking_example_sampler(\n",
    "    tokenizer=llama_tokenizer,\n",
    "    num_samples=600,\n",
    "    data_file=data_file,\n",
    "    # object_file=object_file,\n",
    "    few_shot=False,\n",
    "    alt_examples=True,\n",
    "    # num_ents_or_ops=3,\n",
    "    architecture=\"LLaMAForCausalLM\",\n",
    ")\n",
    "\n",
    "dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_data[0],\n",
    "        \"last_token_indices\": raw_data[1],\n",
    "        \"labels\": raw_data[2],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "\n",
    "print(f\"Length of dataset: {len(dataset)}\")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a177adac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  The machine is in Box X, the magazine is in Box T, the key is in Box A, the fig is in Box E, the bomb is in Box M. Box X contains the\n",
      "Answer:  machine\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(\n",
    "    f\"Prompt: {llama_tokenizer.decode(dataset[idx]['input_ids'][:dataset[idx]['last_token_indices']+1])}\"\n",
    ")\n",
    "print(f\"Answer: {llama_tokenizer.decode(dataset[idx]['labels'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8ba8f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [00:19,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task accuracy: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_count = 0\n",
    "correct_count = 0\n",
    "goat_model.eval()\n",
    "with torch.no_grad():\n",
    "    for _, inputs in tqdm(enumerate(dataloader)):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(goat_model.device)\n",
    "\n",
    "        outputs = goat_model(input_ids=inputs[\"input_ids\"])\n",
    "\n",
    "        for bi in range(inputs[\"labels\"].size(0)):\n",
    "            label = inputs[\"labels\"][bi]\n",
    "            pred = torch.argmax(outputs.logits[bi][inputs[\"last_token_indices\"][bi]])\n",
    "\n",
    "            if label == pred:\n",
    "                correct_count += 1\n",
    "            # else:\n",
    "            #     print(f\"Label: {tokenizer.decode(label)}, Prediction: {tokenizer.decode(pred)}\")\n",
    "            total_count += 1\n",
    "\n",
    "del outputs\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "current_acc = round(correct_count / total_count, 2)\n",
    "print(f\"Task accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "719dc324",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"./new_pp_exps/5_boxes/reverse\"\n",
    "path = root_path + \"/direct_logit_heads.pt\"\n",
    "logit_values = torch.load(path)\n",
    "direct_logit_heads = analysis_utils.compute_topk_components(torch.load(path), k=35, largest=False)\n",
    "\n",
    "path = root_path + \"/heads_affect_direct_logit.pt\"\n",
    "logit_values = torch.load(path)\n",
    "heads_affecting_direct_logit_heads = analysis_utils.compute_topk_components(\n",
    "    torch.load(path), k=10, largest=False\n",
    ")\n",
    "\n",
    "path = root_path + \"/heads_at_query_box_pos.pt\"\n",
    "logit_values = torch.load(path)\n",
    "head_at_query_box_token = analysis_utils.compute_topk_components(\n",
    "    torch.load(path), k=15, largest=False\n",
    ")\n",
    "\n",
    "path = root_path + \"/heads_at_prev_query_box_pos.pt\"\n",
    "logit_values = torch.load(path)\n",
    "heads_at_prev_box_pos = analysis_utils.compute_topk_components(torch.load(path), k=5, largest=False)\n",
    "\n",
    "path = root_path + \"/heads_at_next_token_to_prev_box_token.pt\"\n",
    "logit_values = torch.load(path)\n",
    "heads_at_next_token_to_box_pos = analysis_utils.compute_topk_components(\n",
    "    torch.load(path), k=5, largest=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885dc16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "247e0e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_modules = [[f\"model.layers.{layer}.self_attn.k_proj\", \n",
    "                  f\"model.layers.{layer}.self_attn.q_proj\",\n",
    "                  f\"model.layers.{layer}.self_attn.v_proj\",\n",
    "                 f\"model.layers.{layer}.self_attn.o_proj\"] \n",
    "                 for layer in range(32)]\n",
    "goat_modules = [[f\"base_model.model.model.layers.{layer}.self_attn.k_proj\", \n",
    "                 f\"base_model.model.model.layers.{layer}.self_attn.q_proj\",\n",
    "                 f\"base_model.model.model.layers.{layer}.self_attn.v_proj\",\n",
    "                f\"base_model.model.model.layers.{layer}.self_attn.o_proj\"] \n",
    "                for layer in range(32)]\n",
    "\n",
    "llama_modules = [item for sublist in llama_modules for item in sublist]\n",
    "goat_modules = [item for sublist in goat_modules for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95e4dbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [00:49,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "goat_cache = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for bi, inputs in tqdm(enumerate(dataloader)):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(goat_model.device)\n",
    "\n",
    "        with TraceDict(goat_model, goat_modules, retain_input=True) as cache:\n",
    "            _ = goat_model(inputs[\"input_ids\"])\n",
    "        \n",
    "        for llama_layer, goat_layer in zip(llama_modules, goat_modules):\n",
    "            if \"o_proj\" in llama_layer:\n",
    "                if bi in goat_cache:\n",
    "                    goat_cache[bi][llama_layer] = cache[goat_layer].input.cpu()\n",
    "                else:\n",
    "                    goat_cache[bi] = {}\n",
    "                    goat_cache[bi][llama_layer] = cache[goat_layer].input.cpu()\n",
    "            else:\n",
    "                if bi in goat_cache:\n",
    "                    goat_cache[bi][llama_layer] = cache[goat_layer].output.cpu()\n",
    "                else:\n",
    "                    goat_cache[bi] = {}\n",
    "                    goat_cache[bi][llama_layer] = cache[goat_layer].output.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6007922e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44a686ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_model_patching(inputs, outputs, layer, heads, bi, rel_pos, input_tokens):\n",
    "    if isinstance(inputs, tuple):\n",
    "        inputs = inputs[0]\n",
    "\n",
    "    if isinstance(outputs, tuple):\n",
    "        outputs = outputs[0]\n",
    "\n",
    "    cache = rearrange(\n",
    "                goat_cache[bi][layer],\n",
    "                \"batch seq_len (n_heads d_head) -> batch seq_len n_heads d_head\",\n",
    "                n_heads=llama_model.config.num_attention_heads,\n",
    "            )\n",
    "\n",
    "    curr_layer_heads = [h for l, h in heads if l == int(layer.split(\".\")[2])]\n",
    "    \n",
    "    if \"o_proj\" in layer:\n",
    "        pass\n",
    "#         inputs = rearrange(\n",
    "#                 inputs,\n",
    "#                 \"batch seq_len (n_heads d_head) -> batch seq_len n_heads d_head\",\n",
    "#                 n_heads=llama_model.config.num_attention_heads,\n",
    "#             )\n",
    "#         if rel_pos == -1:\n",
    "#             for batch in range(inputs.size(0)):\n",
    "#                 prev_query_box_pos = analysis_utils.compute_prev_query_box_pos(\n",
    "#                     input_tokens[\"input_ids\"][batch],\n",
    "#                     input_tokens[\"last_token_indices\"][batch]\n",
    "#                 )\n",
    "#                 correct_object_pos = prev_query_box_pos - 3\n",
    "#                 for head in curr_layer_heads:\n",
    "#                     inputs[:, correct_object_pos, head] = cache[:, correct_object_pos, head]\n",
    "            \n",
    "#         else:\n",
    "#             pos = outputs.size(1) - rel_pos - 1\n",
    "#             for head in curr_layer_heads:\n",
    "#                 inputs[:, pos, head] = cache[:, pos, head]\n",
    "\n",
    "#         inputs = rearrange(\n",
    "#                 inputs,\n",
    "#                 \"batch seq_len n_heads d_head -> batch seq_len (n_heads d_head)\",\n",
    "#                 n_heads=llama_model.config.num_attention_heads,\n",
    "#             )\n",
    "#         w_o = llama_model.state_dict()[f\"{layer}.weight\"]\n",
    "#         outputs = einsum(\n",
    "#             inputs, w_o, \"batch seq_len hidden_size, d_model hidden_size -> batch seq_len d_model\"\n",
    "#         )\n",
    "\n",
    "    else:\n",
    "        outputs = rearrange(\n",
    "                outputs,\n",
    "                \"batch seq_len (n_heads d_head) -> batch seq_len n_heads d_head\",\n",
    "                n_heads=llama_model.config.num_attention_heads,\n",
    "            )\n",
    "        \n",
    "#         if \"v_proj\" in layer:\n",
    "#             for batch in range(outputs.size(0)):\n",
    "#                 prev_query_box_pos = analysis_utils.compute_prev_query_box_pos(\n",
    "#                     input_tokens[\"input_ids\"][batch],\n",
    "#                     input_tokens[\"last_token_indices\"][batch]\n",
    "#                 )\n",
    "#                 pos = prev_query_box_pos - 4\n",
    "# #                 pos = outputs.size(1)\n",
    "#                 for head in curr_layer_heads:\n",
    "#                     outputs[batch, pos, head] = cache[batch, pos, head]\n",
    "\n",
    "#         if \"k_proj\" in layer:\n",
    "#             for batch in range(outputs.size(0)):\n",
    "#                 prev_query_box_pos = analysis_utils.compute_prev_query_box_pos(\n",
    "#                     input_tokens[\"input_ids\"][batch],\n",
    "#                     input_tokens[\"last_token_indices\"][batch]\n",
    "#                 )\n",
    "#                 pos = prev_query_box_pos - 4\n",
    "# #                 pos = outputs.size(1) - 2 - 1\n",
    "#                 for head in curr_layer_heads:\n",
    "#                     outputs[batch, pos, head] = cache[batch, pos, head]\n",
    "\n",
    "        if \"v_proj\" in layer:\n",
    "#             object_pos = [i for i in range(2, 35, 7)]\n",
    "#             for batch in range(outputs.size(0)):\n",
    "#                 prev_query_box_pos = analysis_utils.compute_prev_query_box_pos(\n",
    "#                     input_tokens[\"input_ids\"][batch],\n",
    "#                     input_tokens[\"last_token_indices\"][batch]\n",
    "#                 )\n",
    "#                 pos = prev_query_box_pos - 4\n",
    "            for head in curr_layer_heads:\n",
    "                outputs[:, :, head] = cache[:, :, head]\n",
    "\n",
    "        if \"k_proj\" in layer:\n",
    "#             object_pos = [i for i in range(2, 35, 7)]\n",
    "            for head in curr_layer_heads:\n",
    "                outputs[:, :, head] = cache[:, :, head]\n",
    "\n",
    "        if \"q_proj\" in layer:\n",
    "            pos = outputs.size(1) - rel_pos - 1\n",
    "            for head in curr_layer_heads:\n",
    "                outputs[:, pos, head] = cache[:, pos, head]\n",
    "\n",
    "        outputs = rearrange(\n",
    "                    outputs,\n",
    "                    \"batch seq_len n_heads d_head -> batch seq_len (n_heads d_head)\",\n",
    "                    n_heads=llama_model.config.num_attention_heads,\n",
    "                )\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c95c5393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [00:19,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct_count, total_count = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for bi, inputs in tqdm(enumerate(dataloader)):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(goat_model.device)\n",
    "\n",
    "        with TraceDict(llama_model, llama_modules, retain_input=True, edit_output=partial(\n",
    "                                                                        cross_model_patching,\n",
    "                                                                        heads = direct_logit_heads,\n",
    "                                                                        bi = bi,\n",
    "                                                                        rel_pos = 0,\n",
    "                                                                        input_tokens = inputs)) as _:\n",
    "                outputs = llama_model(inputs[\"input_ids\"])\n",
    "        \n",
    "        for batch in range(inputs[\"labels\"].size(0)):\n",
    "            label = inputs[\"labels\"][batch]\n",
    "            pred = torch.argmax(outputs.logits[batch][inputs[\"last_token_indices\"][batch]])\n",
    "\n",
    "            if label == pred:\n",
    "                correct_count += 1\n",
    "            # else:\n",
    "            #     print(f\"Label: {tokenizer.decode(label)}, Prediction: {tokenizer.decode(pred)}\")\n",
    "            total_count += 1\n",
    "        \n",
    "        del outputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "current_acc = round(correct_count / total_count, 2)\n",
    "print(f\"Task accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c6609c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "11926ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_pos = [i for i in range(2, 35, 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f8834172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The block is in Box N, the bus is in Box J, the dress is in Box L, the wire is in Box K, the boot is in Box V. Box K contains the'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_tokenizer.decode(inputs[\"input_ids\"][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
