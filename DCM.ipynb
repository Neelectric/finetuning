{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from baukit import TraceDict\n",
    "from einops import rearrange, einsum\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "import analysis_utils\n",
    "# from model_aligner_script import load_data\n",
    "from counterfactual_datasets.entity_tracking import *\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  3.29s/it]\n"
     ]
    }
   ],
   "source": [
    "path = \"./llama_7b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "model = AutoModelForCausalLM.from_pretrained(path).to(DEVICE)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "model.eval()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HEADS = model.config.num_attention_heads\n",
    "HEAD_SIZE = model.config.hidden_size // NUM_HEADS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desiderata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(raw_data, batch_size):\n",
    "    train_size = int(0.6 * len(raw_data[0]))\n",
    "    eval_size = int(0.4 * len(raw_data[0]))\n",
    "\n",
    "    print(\"Train size: \", train_size)\n",
    "    print(\"Eval size: \", eval_size)\n",
    "    print(\"Test size: \", len(raw_data[0]) - train_size - eval_size)\n",
    "\n",
    "    raw_train = (\n",
    "        raw_data[0][:train_size],\n",
    "        raw_data[1][:train_size],\n",
    "        raw_data[2][:train_size],\n",
    "        raw_data[3][:train_size],\n",
    "        raw_data[4][:train_size],\n",
    "    )\n",
    "    raw_eval = (\n",
    "        raw_data[0][train_size : train_size + eval_size],\n",
    "        raw_data[1][train_size : train_size + eval_size],\n",
    "        raw_data[2][train_size : train_size + eval_size],\n",
    "        raw_data[3][train_size : train_size + eval_size],\n",
    "        raw_data[4][train_size : train_size + eval_size],\n",
    "    )\n",
    "    raw_test = (\n",
    "        raw_data[0][train_size + eval_size :],\n",
    "        raw_data[1][train_size + eval_size :],\n",
    "        raw_data[2][train_size + eval_size :],\n",
    "        raw_data[3][train_size + eval_size :],\n",
    "        raw_data[4][train_size + eval_size :],\n",
    "    )\n",
    "\n",
    "    train_dataset = Dataset.from_dict(\n",
    "        {\n",
    "            \"base_input_ids\": raw_train[0],\n",
    "            \"base_input_last_pos\": raw_train[1],\n",
    "            \"source_input_ids\": raw_train[2],\n",
    "            \"source_input_last_pos\": raw_train[3],\n",
    "            \"labels\": raw_train[4],\n",
    "        }\n",
    "    ).with_format(\"torch\")\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    eval_dataset = Dataset.from_dict(\n",
    "        {\n",
    "            \"base_input_ids\": raw_eval[0],\n",
    "            \"base_input_last_pos\": raw_eval[1],\n",
    "            \"source_input_ids\": raw_eval[2],\n",
    "            \"source_input_last_pos\": raw_eval[3],\n",
    "            \"labels\": raw_eval[4],\n",
    "        }\n",
    "    ).with_format(\"torch\")\n",
    "    eval_dataloader = DataLoader(\n",
    "        eval_dataset,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    test_dataset = Dataset.from_dict(\n",
    "        {\n",
    "            \"base_input_ids\": raw_test[0],\n",
    "            \"base_input_last_pos\": raw_test[1],\n",
    "            \"source_input_ids\": raw_test[2],\n",
    "            \"source_input_last_pos\": raw_test[3],\n",
    "            \"labels\": raw_test[4],\n",
    "        }\n",
    "    ).with_format(\"torch\")\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    return train_dataloader, eval_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = \"./box_datasets/no_instructions/alternative/Random/3/train.jsonl\"\n",
    "object_file_path = \"./box_datasets/filtered_objects_with_bnc_frequency.csv\"\n",
    "\n",
    "raw_data = correct_object_position_fetcher_desiderata(\n",
    "    tokenizer=tokenizer,\n",
    "    num_samples=600,\n",
    "    data_file=data_file_path,\n",
    "    object_file=object_file_path,\n",
    "    num_boxes=3,\n",
    "    alt_format=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  360\n",
      "Eval size:  240\n",
      "Test size:  0\n"
     ]
    }
   ],
   "source": [
    "objValueFetcher_train, objValueFetcher_eval, objValueFetcher_test = load_data(\n",
    "    raw_data=raw_data, batch_size=40\n",
    ")\n",
    "\n",
    "# objValueFetcher_train_2, objValueFetcher_eval_2, objValueFetcher_test_2 = load_data(\n",
    "#     raw_data=raw_data, batch_size=40\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "desiderata_train = [objValueFetcher_train]\n",
    "desiderata_eval = [objValueFetcher_eval]\n",
    "desiderata_test = [objValueFetcher_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The fig is in Box X, the engine is in Box T, the radio is in Box A. Box T contains the\n",
      " There are a bunch of boxes containing objects. The crown is in Box R, the creature is in Box D, the phone is in Box C. Box D contains the\n",
      " engine\n"
     ]
    }
   ],
   "source": [
    "data = next(enumerate(desiderata_train[0]))[1]\n",
    "bi = 1\n",
    "print(tokenizer.decode(data[\"base_input_ids\"][bi][: data[\"base_input_last_pos\"][bi] + 1]))\n",
    "print(tokenizer.decode(data[\"source_input_ids\"][bi][: data[\"source_input_last_pos\"][bi] + 1]))\n",
    "print(tokenizer.decode(data[\"labels\"][bi]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Binary Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = [f\"model.layers.{i}.self_attn.o_proj\" for i in range(32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_activations_train = {}\n",
    "\n",
    "for di, desid_train in enumerate(desiderata_train):\n",
    "    from_activations_train[di] = {}\n",
    "\n",
    "    for bi, inputs in enumerate(desid_train):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(DEVICE)\n",
    "\n",
    "        from_activations_train[di][bi] = {}\n",
    "        with torch.no_grad():\n",
    "            with TraceDict(model, modules, retain_input=True) as trace:\n",
    "                _ = model(inputs[\"source_input_ids\"])\n",
    "\n",
    "                for module in modules:\n",
    "                    if \"self_attn\" in module:\n",
    "                        from_activations_train[di][bi][module] = trace[module].input.detach().cpu()\n",
    "                    else:\n",
    "                        from_activations_train[di][bi][module] = trace[module].output.detach().cpu()\n",
    "\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(\"cpu\")\n",
    "\n",
    "        del trace\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_activations_eval = {}\n",
    "\n",
    "for di, desid_eval in enumerate(desiderata_eval):\n",
    "    from_activations_eval[di] = {}\n",
    "\n",
    "    for bi, inputs in enumerate(desid_eval):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(DEVICE)\n",
    "\n",
    "        from_activations_eval[di][bi] = {}\n",
    "        with torch.no_grad():\n",
    "            with TraceDict(model, modules, retain_input=True) as trace:\n",
    "                _ = model(inputs[\"source_input_ids\"])\n",
    "\n",
    "                for module in modules:\n",
    "                    if \"self_attn\" in module:\n",
    "                        from_activations_eval[di][bi][module] = trace[module].input.detach().cpu()\n",
    "                    else:\n",
    "                        from_activations_eval[di][bi][module] = trace[module].output.detach().cpu()\n",
    "\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(\"cpu\")\n",
    "\n",
    "        del trace\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules_w_heads = []\n",
    "for module in modules:\n",
    "    if \"self_attn\" in module:\n",
    "        for head in range(32):\n",
    "            modules_w_heads.append(f\"{module}.{head}\")\n",
    "    else:\n",
    "        modules_w_heads.append(module)\n",
    "\n",
    "mask_dict = {module: i for i, module in enumerate(modules_w_heads)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_output(\n",
    "    inputs=None,\n",
    "    output=None,\n",
    "    layer=None,\n",
    "    mask=None,\n",
    "    from_activations=None,\n",
    "    to_last_token_pos=None,\n",
    "    from_last_token_pos=None,\n",
    "    rel_pos=None,\n",
    "):\n",
    "    if \"self_attn\" in layer:\n",
    "        inp = inputs[0]\n",
    "        from_activations[layer] = from_activations[layer].to(DEVICE)\n",
    "\n",
    "        # Computing the output of each head in this layer after the intervention\n",
    "        for head_idx in range(NUM_HEADS):\n",
    "            head_start = head_idx * HEAD_SIZE\n",
    "            head_end = (head_idx + 1) * HEAD_SIZE\n",
    "            abl_amt = mask[mask_dict[f\"{layer}.{head_idx}\"]]\n",
    "\n",
    "            for bi in range(inp.shape[0]):\n",
    "                intervention = (\n",
    "                    abl_amt * inp[bi, to_last_token_pos[bi] - rel_pos, head_start:head_end].clone()\n",
    "                    + (1 - abl_amt)\n",
    "                    * from_activations[layer][bi, from_last_token_pos[bi] - rel_pos, head_start:head_end]\n",
    "                )\n",
    "                inp[bi, to_last_token_pos[bi] - rel_pos, head_start:head_end] = intervention\n",
    "\n",
    "        from_activations[layer] = from_activations[layer].to(\"cpu\")\n",
    "\n",
    "        weights = model.state_dict()[f\"{layer}.weight\"]\n",
    "        mod_output = einsum(\n",
    "            inp, weights, \"batch seq_len hidden_size, d_model hidden_size -> batch seq_len d_model\"\n",
    "        )\n",
    "\n",
    "        del weights\n",
    "        torch.cuda.empty_cache()\n",
    "        return mod_output\n",
    "\n",
    "    else:\n",
    "        assert False, \"shouldn't be here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_heads_from_mask(rounded):\n",
    "    masked_heads = []\n",
    "    inverse_mask_dict = {v: k for k, v in mask_dict.items()}\n",
    "\n",
    "    for mask_idx in (rounded == 0).nonzero()[:, 0]:\n",
    "        layer = inverse_mask_dict[mask_idx.item()]\n",
    "        layer_idx = int(layer.split(\".\")[2])\n",
    "        head_idx = int(layer.split(\".\")[-1])\n",
    "        masked_heads.append([layer_idx, head_idx])\n",
    "\n",
    "    return masked_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, bi: 0, Loss: -11.444095611572266, Target logits: 11.444095611572266\n",
      "lamb: 0.1, #Zero heads: 0\n",
      "[]\n",
      "lamb: 0.1, Validation Accuracy: 0.11666666666666667\n",
      "\n",
      "epoch: 0, bi: 2, Loss: -12.54464340209961, Target logits: 12.820212364196777\n",
      "epoch: 0, bi: 4, Loss: -12.65518569946289, Target logits: 13.186975479125977\n",
      "lamb: 0.1, #Zero heads: 1\n",
      "[[14, 27]]\n",
      "lamb: 0.1, Validation Accuracy: 0.22083333333333333\n",
      "\n",
      "epoch: 0, bi: 6, Loss: -12.839062690734863, Target logits: 13.59594440460205\n",
      "epoch: 0, bi: 8, Loss: -13.451740264892578, Target logits: 14.405669212341309\n",
      "lamb: 0.1, #Zero heads: 11\n",
      "[[11, 23], [13, 1], [14, 0], [14, 27], [16, 2], [16, 16], [16, 17], [17, 25], [19, 12], [19, 18], [29, 24]]\n",
      "lamb: 0.1, Validation Accuracy: 0.7333333333333333\n",
      "\n",
      "epoch: 1, bi: 0, Loss: -12.849929809570312, Target logits: 13.886326789855957\n",
      "lamb: 0.1, #Zero heads: 11\n",
      "[[11, 23], [13, 1], [14, 0], [14, 27], [16, 2], [16, 16], [16, 17], [17, 25], [19, 12], [19, 18], [29, 24]]\n",
      "lamb: 0.1, Validation Accuracy: 0.7333333333333333\n",
      "\n",
      "epoch: 1, bi: 2, Loss: -13.446890830993652, Target logits: 14.569879531860352\n",
      "epoch: 1, bi: 4, Loss: -13.396492958068848, Target logits: 14.50238037109375\n",
      "lamb: 0.1, #Zero heads: 12\n",
      "[[11, 23], [13, 1], [14, 0], [14, 27], [16, 2], [16, 16], [16, 17], [17, 25], [19, 12], [19, 18], [29, 24], [31, 29]]\n",
      "lamb: 0.1, Validation Accuracy: 0.7333333333333333\n",
      "\n",
      "epoch: 1, bi: 6, Loss: -13.3612642288208, Target logits: 14.430119514465332\n",
      "epoch: 1, bi: 8, Loss: -13.67523193359375, Target logits: 14.706158638000488\n",
      "lamb: 0.1, #Zero heads: 10\n",
      "[[11, 23], [13, 1], [14, 0], [14, 27], [16, 2], [16, 16], [16, 17], [17, 25], [19, 12], [31, 29]]\n",
      "lamb: 0.1, Validation Accuracy: 0.7416666666666667\n",
      "\n",
      "epoch: 2, bi: 0, Loss: -12.986468315124512, Target logits: 13.995262145996094\n",
      "lamb: 0.1, #Zero heads: 10\n",
      "[[11, 23], [13, 1], [14, 0], [14, 27], [16, 2], [16, 16], [16, 17], [17, 25], [19, 12], [31, 29]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">77</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">74 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   </span>rel_pos=rel_pos,                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">75 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   </span>),                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">76 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   </span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> _:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>77 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   </span>eval_output = model(eval_inputs[<span style=\"color: #808000; text-decoration-color: #808000\">\"base_input_ids\"</span>].to    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">78 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">79 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> idx <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(eval_inputs[<span style=\"color: #808000; text-decoration-color: #808000\">\"base_input_ids\"</span>].size(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>)):    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">80 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   </span>target = eval_inputs[<span style=\"color: #808000; text-decoration-color: #808000\">\"labels\"</span>][idx]                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">150</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/transformers/models/llama/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">mode</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ling_llama.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">765</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">762 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>return_dict = return_dict <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> return_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.use_return   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">763 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">764 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>765 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model(                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">766 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>input_ids=input_ids,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">767 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>attention_mask=attention_mask,                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">768 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>past_key_values=past_key_values,                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">150</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/transformers/models/llama/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">mode</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ling_llama.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">614</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">611 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">612 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>)                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">613 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>614 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>layer_outputs = decoder_layer(                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">615 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>hidden_states,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">616 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>attention_mask=attention_mask,                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">617 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>past_key_value=past_key_value,                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">150</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/transformers/models/llama/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">mode</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ling_llama.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">309</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">306 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>hidden_states = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.input_layernorm(hidden_states)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">307 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">308 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Self Attention</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>309 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>hidden_states, self_attn_weights, present_key_value = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.self_attn(              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">310 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>hidden_states=hidden_states,                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">311 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>past_key_value=past_key_value,                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">312 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>attention_mask=attention_mask,                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">150</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/transformers/models/llama/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">mode</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ling_llama.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">258</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">255 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>attn_output = attn_output.transpose(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">256 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>attn_output = attn_output.reshape(bsz, q_len, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.hidden_size)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">257 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>258 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>attn_output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.o_proj(attn_output)                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">259 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">260 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> output_attentions:                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">261 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>attn_weights = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">154</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1544 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> hook_id <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks_with_kwargs:                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1545 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>hook_result = hook(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, args, kwargs, result)                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1546 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1547 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>hook_result = hook(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, args, result)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1548 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1549 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> hook_result <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1550 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>result = hook_result                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/baukit/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">nethook.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">73</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">retain_hook</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 70 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 71 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">retain_hook</span>(m, inputs, output):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 72 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> edit_output:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 73 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>output = invoke_with_optional_args(                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 74 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>edit_output, output=output, layer=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.layer, inputs=inputs            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 75 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>)                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 76 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> retain_input:                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/baukit/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">nethook.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">471</span> in       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">invoke_with_optional_args</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">468 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Pass remaining positional args if they can be accepted.</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">469 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> argspec.varargs <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">470 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>pass_args += <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(args[used_pos:])                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>471 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fn(*pass_args, **pass_kw)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">472 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">edit_output</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">23</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">20 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> bi <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(inp.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]):                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>intervention = (                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>23 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>abl_amt * inp[bi, to_last_token_pos[bi] - rel_pos, head_start:head_e    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">24 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>+ (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> - abl_amt)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">25 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>* from_activations[layer][bi, from_last_token_pos[bi] - rel_pos, hea    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>)                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m77\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m74 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   \u001b[0mrel_pos=rel_pos,                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m75 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   \u001b[0m),                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m76 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   \u001b[0m) \u001b[94mas\u001b[0m _:                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m77 \u001b[2m│   │   │   │   │   │   │   │   │   \u001b[0meval_output = model(eval_inputs[\u001b[33m\"\u001b[0m\u001b[33mbase_input_ids\u001b[0m\u001b[33m\"\u001b[0m].to    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m78 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m79 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   \u001b[0m\u001b[94mfor\u001b[0m idx \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(eval_inputs[\u001b[33m\"\u001b[0m\u001b[33mbase_input_ids\u001b[0m\u001b[33m\"\u001b[0m].size(\u001b[94m0\u001b[0m)):    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m80 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   \u001b[0mtarget = eval_inputs[\u001b[33m\"\u001b[0m\u001b[33mlabels\u001b[0m\u001b[33m\"\u001b[0m][idx]                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m150\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m1\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/transformers/models/llama/\u001b[0m\u001b[1;33mmode\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mling_llama.py\u001b[0m:\u001b[94m765\u001b[0m in \u001b[92mforward\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m762 \u001b[0m\u001b[2m│   │   \u001b[0mreturn_dict = return_dict \u001b[94mif\u001b[0m return_dict \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m.config.use_return   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m763 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m764 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m765 \u001b[2m│   │   \u001b[0moutputs = \u001b[96mself\u001b[0m.model(                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m766 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids=input_ids,                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m767 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m768 \u001b[0m\u001b[2m│   │   │   \u001b[0mpast_key_values=past_key_values,                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m150\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m1\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/transformers/models/llama/\u001b[0m\u001b[1;33mmode\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mling_llama.py\u001b[0m:\u001b[94m614\u001b[0m in \u001b[92mforward\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m611 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mNone\u001b[0m,                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m612 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m613 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m614 \u001b[2m│   │   │   │   \u001b[0mlayer_outputs = decoder_layer(                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m615 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mhidden_states,                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m616 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mattention_mask=attention_mask,                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m617 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mpast_key_value=past_key_value,                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m150\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m1\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/transformers/models/llama/\u001b[0m\u001b[1;33mmode\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mling_llama.py\u001b[0m:\u001b[94m309\u001b[0m in \u001b[92mforward\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m306 \u001b[0m\u001b[2m│   │   \u001b[0mhidden_states = \u001b[96mself\u001b[0m.input_layernorm(hidden_states)                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m307 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m308 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Self Attention\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m309 \u001b[2m│   │   \u001b[0mhidden_states, self_attn_weights, present_key_value = \u001b[96mself\u001b[0m.self_attn(              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m310 \u001b[0m\u001b[2m│   │   │   \u001b[0mhidden_states=hidden_states,                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m311 \u001b[0m\u001b[2m│   │   │   \u001b[0mpast_key_value=past_key_value,                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m312 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m150\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m1\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/transformers/models/llama/\u001b[0m\u001b[1;33mmode\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mling_llama.py\u001b[0m:\u001b[94m258\u001b[0m in \u001b[92mforward\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m255 \u001b[0m\u001b[2m│   │   \u001b[0mattn_output = attn_output.transpose(\u001b[94m1\u001b[0m, \u001b[94m2\u001b[0m)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m256 \u001b[0m\u001b[2m│   │   \u001b[0mattn_output = attn_output.reshape(bsz, q_len, \u001b[96mself\u001b[0m.hidden_size)                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m257 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m258 \u001b[2m│   │   \u001b[0mattn_output = \u001b[96mself\u001b[0m.o_proj(attn_output)                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m259 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m260 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m output_attentions:                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m261 \u001b[0m\u001b[2m│   │   │   \u001b[0mattn_weights = \u001b[94mNone\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m154\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m7\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1544 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m hook_id \u001b[95min\u001b[0m \u001b[96mself\u001b[0m._forward_hooks_with_kwargs:                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1545 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mhook_result = hook(\u001b[96mself\u001b[0m, args, kwargs, result)                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1546 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1547 \u001b[2m│   │   │   │   │   \u001b[0mhook_result = hook(\u001b[96mself\u001b[0m, args, result)                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1548 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1549 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m hook_result \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1550 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mresult = hook_result                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/baukit/\u001b[0m\u001b[1;33mnethook.py\u001b[0m:\u001b[94m73\u001b[0m in        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mretain_hook\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 70 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 71 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mretain_hook\u001b[0m(m, inputs, output):                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 72 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m edit_output:                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 73 \u001b[2m│   │   │   │   \u001b[0moutput = invoke_with_optional_args(                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 74 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0medit_output, output=output, layer=\u001b[96mself\u001b[0m.layer, inputs=inputs            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 75 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 76 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m retain_input:                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/baukit/\u001b[0m\u001b[1;33mnethook.py\u001b[0m:\u001b[94m471\u001b[0m in       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92minvoke_with_optional_args\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m468 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Pass remaining positional args if they can be accepted.\u001b[0m                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m469 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m argspec.varargs \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m470 \u001b[0m\u001b[2m│   │   \u001b[0mpass_args += \u001b[96mlist\u001b[0m(args[used_pos:])                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m471 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m fn(*pass_args, **pass_kw)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m472 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92medit_output\u001b[0m:\u001b[94m23\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m20 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m21 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m bi \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(inp.shape[\u001b[94m0\u001b[0m]):                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m22 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mintervention = (                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m23 \u001b[2m│   │   │   │   │   \u001b[0mabl_amt * inp[bi, to_last_token_pos[bi] - rel_pos, head_start:head_e    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m24 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m+ (\u001b[94m1\u001b[0m - abl_amt)                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m25 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m* from_activations[layer][bi, from_last_token_pos[bi] - rel_pos, hea    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m26 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = {}\n",
    "epochs = 3\n",
    "rel_pos = 0\n",
    "log_steps = 2\n",
    "eval_steps = 4\n",
    "save_path = \"./masks/reverse/last_pos_new/correct_object_position_fetcher_new\"\n",
    "\n",
    "for lamb in [0.1, 0.15, 0.2, 0.25, 0.3]:\n",
    "    mask[lamb] = torch.ones(\n",
    "        len(modules_w_heads), requires_grad=True, device=DEVICE, dtype=torch.float\n",
    "    )\n",
    "    optimizer = torch.optim.Adam([mask[lamb]], lr=1e-1)\n",
    "    eval_acc = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for di, desid_train in enumerate(desiderata_train):\n",
    "            for bi, inputs in enumerate(desid_train):\n",
    "                mask[lamb].data.clamp_(0, 1)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with TraceDict(\n",
    "                    model,\n",
    "                    modules,\n",
    "                    edit_output=partial(\n",
    "                        edit_output,\n",
    "                        mask=mask[lamb],\n",
    "                        from_activations=from_activations_train[di][bi],\n",
    "                        to_last_token_pos=inputs[\"base_input_last_pos\"],\n",
    "                        from_last_token_pos=inputs[\"source_input_last_pos\"],\n",
    "                        rel_pos=rel_pos,\n",
    "                    ),\n",
    "                ) as _:\n",
    "                    output = model(inputs[\"base_input_ids\"].to(DEVICE))\n",
    "\n",
    "                target_logits = 0\n",
    "                for idx in range(inputs[\"base_input_ids\"].size(0)):\n",
    "                    target = inputs[\"labels\"][idx]\n",
    "                    target_logits += output.logits[idx, inputs[\"base_input_last_pos\"][idx], target]\n",
    "                target_logits /= inputs[\"base_input_ids\"].size(0)\n",
    "\n",
    "                # maximize the target logits => minimize the negative target logits\n",
    "                # minimize the number of heads => maximize #ones in the mask\n",
    "                loss = -target_logits + lamb * torch.sum(1 - mask[lamb])\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if bi % log_steps == 0:\n",
    "                    print(\n",
    "                        f\"epoch: {epoch}, bi: {bi}, Loss: {loss.item()}, Target logits: {target_logits.item()}\"\n",
    "                    )\n",
    "                \n",
    "                if bi % eval_steps == 0:\n",
    "                    with torch.inference_mode():\n",
    "                        mask_data = mask[lamb].data.clone()\n",
    "                        mask_data.clamp_(0, 1)\n",
    "                        rounded = torch.round(mask_data)\n",
    "                        heads = compute_heads_from_mask(rounded)\n",
    "                        print(f\"lamb: {lamb}, #Zero heads: {(rounded == 0).nonzero().shape[0]}\")\n",
    "                        print(heads)\n",
    "\n",
    "                        correct, total = 0, 0\n",
    "                        for eval_di, desid_eval in enumerate(desiderata_eval):\n",
    "                            for eval_bi, eval_inputs in enumerate(desid_eval):\n",
    "                                with TraceDict(\n",
    "                                    model,\n",
    "                                    modules,\n",
    "                                    edit_output=partial(\n",
    "                                        edit_output,\n",
    "                                        mask=rounded,\n",
    "                                        from_activations=from_activations_eval[eval_di][eval_bi],\n",
    "                                        to_last_token_pos=eval_inputs[\"base_input_last_pos\"],\n",
    "                                        from_last_token_pos=eval_inputs[\"source_input_last_pos\"],\n",
    "                                        rel_pos=rel_pos,\n",
    "                                    ),\n",
    "                                ) as _:\n",
    "                                    eval_output = model(eval_inputs[\"base_input_ids\"].to(DEVICE))\n",
    "\n",
    "                                for idx in range(eval_inputs[\"base_input_ids\"].size(0)):\n",
    "                                    target = eval_inputs[\"labels\"][idx]\n",
    "                                    pred = torch.argmax(eval_output.logits[idx, eval_inputs[\"base_input_last_pos\"][idx]])\n",
    "\n",
    "                                    if target == pred:\n",
    "                                        correct += 1\n",
    "                                    total += 1\n",
    "\n",
    "                                del eval_output\n",
    "                                torch.cuda.empty_cache()\n",
    "\n",
    "                        acc = correct / total\n",
    "                        if acc > eval_acc:\n",
    "                            eval_acc = acc\n",
    "                            torch.save(mask[lamb].data, f\"{save_path}/{lamb}\")\n",
    "\n",
    "                        print(f\"lamb: {lamb}, Validation Accuracy: {acc}\\n\")\n",
    "\n",
    "            del output\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Learned Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = [f\"model.layers.{i}.self_attn.o_proj\" for i in range(model.config.num_hidden_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_activations_eval = {}\n",
    "\n",
    "for di, desid_test in enumerate(desiderata_test):\n",
    "    from_activations_eval[di] = {}\n",
    "\n",
    "    for bi, inputs in enumerate(desid_test):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(DEVICE)\n",
    "\n",
    "        from_activations_eval[di][bi] = {}\n",
    "        with torch.no_grad():\n",
    "            with TraceDict(model, modules, retain_input=True) as trace:\n",
    "                _ = model(inputs[\"source_input_ids\"])\n",
    "\n",
    "                for module in modules:\n",
    "                    if \"self_attn\" in module:\n",
    "                        from_activations_eval[di][bi][module] = trace[module].input.detach().cpu()\n",
    "                    else:\n",
    "                        from_activations_eval[di][bi][module] = trace[module].output.detach().cpu()\n",
    "\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(\"cpu\")\n",
    "\n",
    "        del trace\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb: 0.05, #Zero heads: 15\n",
      "[[8, 4], [11, 23], [12, 23], [13, 27], [14, 0], [14, 1], [14, 27], [15, 18], [15, 29], [16, 16], [16, 17], [19, 12], [20, 26], [31, 14], [31, 26]]\n",
      "lamb: 0.05, Test Accuracy: 0.775\n",
      "\n",
      "lamb: 0.1, #Zero heads: 6\n",
      "[[11, 23], [12, 23], [14, 0], [14, 27], [31, 14], [31, 26]]\n",
      "lamb: 0.1, Test Accuracy: 0.6916666666666667\n",
      "\n",
      "lamb: 0.15, #Zero heads: 6\n",
      "[[11, 23], [12, 23], [14, 0], [14, 27], [31, 14], [31, 26]]\n",
      "lamb: 0.15, Test Accuracy: 0.6916666666666667\n",
      "\n",
      "lamb: 0.2, #Zero heads: 4\n",
      "[[11, 23], [12, 23], [14, 27], [31, 14]]\n",
      "lamb: 0.2, Test Accuracy: 0.5416666666666666\n",
      "\n",
      "lamb: 0.25, #Zero heads: 4\n",
      "[[11, 23], [12, 23], [14, 27], [31, 14]]\n",
      "lamb: 0.25, Test Accuracy: 0.5416666666666666\n",
      "\n",
      "lamb: 0.3, #Zero heads: 3\n",
      "[[11, 23], [14, 27], [31, 14]]\n",
      "lamb: 0.3, Test Accuracy: 0.4166666666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = './masks/reverse/last_pos_new/box_label_value_fetcher/'\n",
    "masks = sorted([float(mask) for mask in os.listdir(path) if '.png' not in mask])\n",
    "rel_pos = 0\n",
    "\n",
    "num_heads, valid_acc = [], []\n",
    "for lamb in masks:\n",
    "    with torch.no_grad():\n",
    "        mask = torch.load(f\"{path}/{lamb}\")\n",
    "        mask.clamp_(0, 1)\n",
    "        rounded = torch.round(mask.data)\n",
    "        heads = compute_heads_from_mask(rounded)\n",
    "        print(f\"lamb: {lamb}, #Zero heads: {(rounded == 0).nonzero().shape[0]}\")\n",
    "        print(heads)\n",
    "\n",
    "        correct, total = 0, 0\n",
    "        for di, desid_test in enumerate(desiderata_test):\n",
    "            for bi, inputs in enumerate(desid_test):\n",
    "                with TraceDict(\n",
    "                    model,\n",
    "                    modules,\n",
    "                    edit_output=partial(\n",
    "                        edit_output,\n",
    "                        mask=rounded,\n",
    "                        from_activations=from_activations_eval[di][bi],\n",
    "                        to_last_token_pos=inputs[\"base_input_last_pos\"],\n",
    "                        from_last_token_pos=inputs[\"source_input_last_pos\"],\n",
    "                        rel_pos=rel_pos,\n",
    "                    ),\n",
    "                ) as _:\n",
    "                    output = model(inputs[\"base_input_ids\"].to(DEVICE))\n",
    "\n",
    "                for idx in range(inputs[\"base_input_ids\"].size(0)):\n",
    "                    target = inputs[\"labels\"][idx]\n",
    "                    pred = torch.argmax(output.logits[idx, inputs[\"base_input_last_pos\"][idx]])\n",
    "\n",
    "                    if target == pred:\n",
    "                        correct += 1\n",
    "                    total += 1\n",
    "\n",
    "                del output\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        num_heads.append((rounded == 0).nonzero().shape[0])\n",
    "        valid_acc.append(correct / total)\n",
    "        print(f\"lamb: {lamb}, Test Accuracy: {correct / total}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb: 0.05, #Zero heads: 15\n",
      "[[11, 23], [12, 23], [12, 25], [13, 1], [14, 0], [14, 1], [14, 27], [16, 2], [16, 16], [17, 25], [19, 12], [19, 18], [25, 24], [26, 19], [29, 24]]\n",
      "lamb: 0.1, #Zero heads: 9\n",
      "[[11, 23], [12, 23], [13, 1], [14, 0], [14, 27], [16, 2], [17, 25], [19, 12], [29, 24]]\n",
      "lamb: 0.15, #Zero heads: 6\n",
      "[[11, 23], [13, 1], [14, 0], [14, 27], [16, 2], [19, 12]]\n",
      "lamb: 0.2, #Zero heads: 5\n",
      "[[13, 1], [14, 0], [14, 27], [16, 2], [19, 12]]\n"
     ]
    }
   ],
   "source": [
    "path = './masks/reverse/last_pos_new/correct_object_position_fetcher/'\n",
    "masks = sorted([float(mask) for mask in os.listdir(path) if '.png' not in mask])\n",
    "rel_pos = 0\n",
    "\n",
    "num_heads, valid_acc = [], []\n",
    "for lamb in masks:\n",
    "    with torch.no_grad():\n",
    "        mask = torch.load(f\"{path}/{lamb}\")\n",
    "        mask.clamp_(0, 1)\n",
    "        rounded = torch.round(mask.data)\n",
    "        heads = compute_heads_from_mask(rounded)\n",
    "        print(f\"lamb: {lamb}, #Zero heads: {(rounded == 0).nonzero().shape[0]}\")\n",
    "        print(heads)\n",
    "\n",
    "        # correct, total = 0, 0\n",
    "        # for di, desid_test in enumerate(desiderata_test):\n",
    "        #     for bi, inputs in enumerate(desid_test):\n",
    "        #         with TraceDict(\n",
    "        #             model,\n",
    "        #             modules,\n",
    "        #             edit_output=partial(\n",
    "        #                 edit_output,\n",
    "        #                 mask=rounded,\n",
    "        #                 from_activations=from_activations_eval[di][bi],\n",
    "        #                 to_last_token_pos=inputs[\"base_input_last_pos\"],\n",
    "        #                 from_last_token_pos=inputs[\"source_input_last_pos\"],\n",
    "        #                 rel_pos=rel_pos,\n",
    "        #             ),\n",
    "        #         ) as _:\n",
    "        #             output = model(inputs[\"base_input_ids\"].to(DEVICE))\n",
    "\n",
    "        #         for idx in range(inputs[\"base_input_ids\"].size(0)):\n",
    "        #             target = inputs[\"labels\"][idx]\n",
    "        #             pred = torch.argmax(output.logits[idx, inputs[\"base_input_last_pos\"][idx]])\n",
    "\n",
    "        #             if target == pred:\n",
    "        #                 correct += 1\n",
    "        #             total += 1\n",
    "\n",
    "        #         del output\n",
    "        #         torch.cuda.empty_cache()\n",
    "\n",
    "        # num_heads.append((rounded == 0).nonzero().shape[0])\n",
    "        # valid_acc.append(correct / total)\n",
    "        # print(f\"lamb: {lamb}, Test Accuracy: {correct / total}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[11, 23], [12, 23], [14, 27], [31, 14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABgRUlEQVR4nO3deVhU1f8H8PewDruyL8qiuEC4oibuS+5bZrnlvpSaqaGZVuaSuZVmVmL2c8mstExLcyW3LDI33MJdFFQQAQUEgWHm/P7gy+Q4A85F4MLwfj0Pz+OcOffOZz4O8OGcc+9RCCEEiIiIiEyEmdwBEBEREZUkFjdERERkUljcEBERkUlhcUNEREQmhcUNERERmRQWN0RERGRSWNwQERGRSWFxQ0RERCaFxQ0RERGZFBY3VK6cPXsWI0eOREBAAJRKJezt7dG4cWMsWbIEqampcocn2Z07dzBnzhycPn1a0nEXLlzAiBEj4OvrCysrK7i6uqJ79+7YvXu3Xt/169dDoVDgxIkTTz3viBEj4O/vLykWKXbt2oU5c+Y8tZ9KpYKHhweaN29eaB+NRgNfX1/Ur1/f6Nc/dOgQFAoFDh06ZPQxJWXOnDlQKBQGv7744gtJ5/r++++xfPnyYseiUCgwceLEYh9fEoqKYcuWLbL9P924cQMKhQLr168v89emssPihsqNr7/+GqGhoTh+/Djefvtt7NmzB9u2bcMrr7yCVatWYfTo0XKHKNmdO3cwd+5cScXN1q1b0ahRIxw7dgyzZs3C77//joiICABA9+7dMX369GLHM2vWLGzbtq3Yxz/Nrl27MHfu3Kf2s7S0xNChQ/HPP/8gJibGYJ/ff/8d8fHxFe7/fc+ePfj77791vl555RVJ53jW4oaosrOQOwAiAPj7778xfvx4dOrUCb/88gusra21z3Xq1AlTp07Fnj17SuS1srKyYGtrq9euVquRl5en89pl7dq1axg6dCjq1auHQ4cOwc7OTvvcK6+8gvHjx+Pjjz9G48aNMXDgQMnnr1mzZkmG+0xGjx6NpUuXYu3atfjkk0/0nl+7di2srKwwZMgQGaIrvtDQULi6usodRqlTqVRQKBSwsOCvESp/OHJD5cKCBQugUCiwevVqg8WFlZUVevfurX2s0WiwZMkS1K1bF9bW1nB3d8ewYcNw69YtnePatWuHkJAQ/PHHH2jRogVsbW0xatQo7dD0kiVLMH/+fAQEBMDa2hoHDx4EAJw4cQK9e/eGs7MzlEolGjVqhB9//FEvrtu3b+O1115D9erVYWVlBW9vb7z88su4e/cuDh06hKZNmwIARo4cqZ2iKGra5tNPP0VWVhY+//xzncKmwNKlS1GlShV89NFHes/dv38fI0eOhLOzM+zs7NCrVy9cv35dp4+haSkhBFauXImGDRvCxsYGVatWxcsvv6x3LJA/KtGxY0c4OTnB1tYWQUFBWLhwofbcX375JQDoTMncuHHD4HsNCgpCWFgYvv32W+Tl5ek89+DBA/z666/o06cPXFxccOLECQwcOBD+/v6wsbGBv78/Bg0ahJs3bxaaywLt2rVDu3bt9NoN5SI3Nxfz58/Xfq7c3NwwcuRI3Lt376mvYwxjct2uXTvs3LkTN2/e1MljgZycHMybNw9BQUFQKpVwcXFB+/btERUVpfd63377LYKCgmBra4sGDRrgt99+0+tz5coVDB48GO7u7rC2tkZQUJD2/7FAwXTft99+i6lTp8LHxwfW1ta4evVqieSlgDHfd/fu3cOECRMQHBwMe3t7uLu7o0OHDjhy5Ije+e7cuYP+/fvDwcEBTk5OGDBgABITE/X6Xb9+HQMHDoS3tzesra3h4eGBjh07Sp5OpvKDJTfJTq1W48CBAwgNDUX16tWNOmb8+PFYvXo1Jk6ciJ49e+LGjRuYNWsWDh06hFOnTun85ZyQkIAhQ4Zg+vTpWLBgAczM/qvpV6xYgdq1a+OTTz6Bo6MjatWqhYMHD6Jr1654/vnnsWrVKjg5OWHTpk0YMGAAsrKyMGLECAD5hU3Tpk2hUqnw7rvvon79+khJScHevXtx//59NG7cGOvWrcPIkSPx/vvvo0ePHgCAatWqFfq+IiMji1yLYmtri86dO+PHH39EYmIiPD09tc+NHj0anTp1wvfff4/4+Hi8//77aNeuHc6ePYsqVaoU+pqvv/461q9fj0mTJmHx4sVITU3FvHnz0KJFC5w5cwYeHh4AgDVr1mDs2LFo27YtVq1aBXd3d1y+fBnnz58HkD/llZmZiS1btuDvv//Wnt/Ly6vQ1x49ejTGjBmDnTt3ok+fPtr277//HtnZ2dopqRs3bqBOnToYOHAgnJ2dkZCQgIiICDRt2hQxMTElMlKi0WjQp08fHDlyBNOnT0eLFi1w8+ZNzJ49G+3atcOJEydgY2Pz1PMUjAAWUCgUMDc3B2BcrleuXInXXnsN165d05tCzMvLQ7du3XDkyBFMmTIFHTp0QF5eHo4ePYq4uDi0aNFC23fnzp04fvw45s2bB3t7eyxZsgR9+/bFpUuXUKNGDQBATEwMWrRoAV9fXyxduhSenp7Yu3cvJk2ahOTkZMyePVvn9WfOnImwsDCsWrUKZmZmcHd3LzIXQgi9wrUg108y9vuuYO3d7Nmz4enpiYcPH2Lbtm1o164d9u/fry1kHz16hBdeeAF37tzBwoULUbt2bezcuRMDBgzQe+3u3btDrVZjyZIl8PX1RXJyMqKiovDgwYMi3x+VY4JIZomJiQKAGDhwoFH9L1y4IACICRMm6LT/888/AoB49913tW1t27YVAMT+/ft1+sbGxgoAombNmiI3N1fnubp164pGjRoJlUql096zZ0/h5eUl1Gq1EEKIUaNGCUtLSxETE1NorMePHxcAxLp164x6b0qlUjRv3rzIPu+8844AIP755x8hhBDr1q0TAETfvn11+v31118CgJg/f762bfjw4cLPz0/7+O+//xYAxNKlS3WOjY+PFzY2NmL69OlCCCEyMjKEo6OjaNWqldBoNIXG9sYbbwgpP1YyMjKEvb296N27t057aGioqF69ujbXT8rLyxMPHz4UdnZ24rPPPtO2Hzx4UAAQBw8e1La1bdtWtG3bVu8cT+bihx9+EADEzz//rNOv4P9w5cqVRb6X2bNnCwB6Xz4+PkII43MthBA9evTQia3Ahg0bBADx9ddfFxkLAOHh4SHS09O1bYmJicLMzEwsXLhQ29alSxdRrVo1kZaWpnP8xIkThVKpFKmpqUKI//Lapk2bIl/3yRie9vX4/5Ox33dPysvLEyqVSnTs2FHneyAiIkIAEL/++qtO/7Fjx+p8TyYnJwsAYvny5Ua/Nyr/OC1FFU7B1FHBX3IFmjVrhqCgIOzfv1+nvWrVqujQoYPBc/Xu3RuWlpbax1evXsXFixfx6quvAsj/S7ngq3v37khISMClS5cAALt370b79u0RFBRUUm/NKEIIANCZqgCgjblAixYt4Ofnp82XIb/99hsUCgWGDBmi8149PT3RoEED7dUsUVFRSE9Px4QJE/Re91nY29ujf//+2LVrF+7evQsAOH/+PE6ePIkRI0ZoR9kePnyId955B4GBgbCwsICFhQXs7e2RmZmJCxculEgsv/32G6pUqYJevXrp5KJhw4bw9PQ0+sqe33//HcePH9d+7dq1S3t+Y3JdlN27d0OpVGLUqFFP7du+fXs4ODhoH3t4eMDd3V07lZednY39+/ejb9++sLW11fusZ2dn4+jRozrn7Nevn1E5KNC/f3+dXBR8LV68WKeflO87AFi1ahUaN24MpVIJCwsLWFpaYv/+/TqfhYMHD8LBwUFnOhsABg8erPPY2dkZNWvWxMcff4xly5YhOjra4MgSVSycliLZubq6wtbWFrGxsUb1T0lJAWB4usPb21tvHUZR0yJPPlfwC3batGmYNm2awWOSk5MB5M/9FzXFVBy+vr5PzUPBGpYnp/Aen6J6vK0gX4bcvXsXQgjt1NOTCqYvCtaclPT7BfKnptauXYtvv/0W06ZNw9q1a6FQKDBy5Ehtn8GDB2P//v2YNWsWmjZtCkdHRygUCnTv3h2PHj0qkTju3r2LBw8ewMrKyuDzBf/vT9OgQQOD02TG5roo9+7dg7e3t87UamFcXFz02qytrbX5SklJQV5eHj7//HN8/vnnBs/x5Hsu6nvJEDc3NzRp0kSv/cl1WFK+75YtW4apU6di3Lhx+PDDD+Hq6gpzc3PMmjVLp7hJSUkxmOsnv08UCgX279+PefPmYcmSJZg6dSqcnZ3x6quv4qOPPtIpEKniYHFDsjM3N0fHjh2xe/du3Lp166m/QAt+aCckJOj1vXPnjt4vlqJGGp58ruDYmTNn4qWXXjJ4TJ06dQDk/+B+cgHzs+rUqRO+/PJLHD161OC6m6ysLERGRiIkJETvh7ShhZKJiYkIDAws9PVcXV2hUChw5MgRgwu5C9rc3NwAoMTfL5A/whQUFIR169Zh8uTJ2LhxIzp06ICAgAAAQFpaGn777TfMnj0bM2bM0B6Xk5Nj1L2PlEol0tLS9Nqf/MXt6uoKFxeXQq/Ke9Zfcsbmuihubm74888/odFojCpwilK1alWYm5tj6NCheOONNwz2Kfg/KFCSo3aPk/J9t3HjRrRr1057e4QCGRkZOo9dXFxw7NgxvfMY+j7x8/PDmjVrAACXL1/Gjz/+iDlz5iA3NxerVq2S/oZIdpyWonJh5syZEEJg7NixyM3N1XtepVJhx44dAKCdYtq4caNOn+PHj+PChQvo2LFjseOoU6cOatWqhTNnzqBJkyYGvwp+yXXr1g0HDx7UGS5/UsEvLGNHF9566y3Y2NjgzTffRGZmpt7z06ZNw/379/H+++/rPffdd9/pPI6KisLNmzcNXilUoGfPnhBC4Pbt2wbfa7169QDkFyBOTk5YtWqVdlrMEKnvt8CoUaMQExOD999/H/fu3dOZdlEoFBBC6P3y/7//+z+o1eqnntvf3x+XL19GTk6Oti0lJUXv6qKePXsiJSUFarXaYC4KfrkWl7G5BnRHWB7XrVs3ZGdnl8gN6GxtbdG+fXtER0ejfv36BmMyNPpTGqR83ykUCr3PwtmzZ3UWsQP503IZGRnYvn27Tvv3339fZCy1a9fG+++/j3r16uHUqVMl8O5IDhy5oXIhLCwMERERmDBhAkJDQzF+/Hg899xzUKlUiI6OxurVqxESEoJevXqhTp06eO211/D555/DzMwM3bp1014tVb16dbz11lvPFMtXX32Fbt26oUuXLhgxYgR8fHyQmpqKCxcu4NSpU/jpp58AAPPmzcPu3bvRpk0bvPvuu6hXrx4ePHiAPXv2IDw8HHXr1kXNmjVhY2OD7777DkFBQbC3t4e3tze8vb0NvnbNmjXx7bff4tVXX0XTpk0RHh6OOnXq4O7du1i7di12796NadOmGbzi48SJExgzZgxeeeUVxMfH47333oOPjw8mTJhQ6Htt2bIlXnvtNYwcORInTpxAmzZtYGdnh4SEBPz555+oV68exo8fD3t7eyxduhRjxozBCy+8gLFjx8LDwwNXr17FmTNntHfgLfgFvXjxYnTr1g3m5uaoX79+oVM9BYYNG4Z3330XH3/8MapUqaLz17ujoyPatGmDjz/+GK6urvD398fhw4exZs2aIq8CKzB06FB89dVXGDJkCMaOHYuUlBQsWbIEjo6OOv0GDhyI7777Dt27d8fkyZPRrFkzWFpa4tatWzh48CD69OmDvn37PvX1CmNsroH8PG7duhUREREIDQ2FmZkZmjRpgkGDBmHdunUYN24cLl26hPbt20Oj0eCff/5BUFCQ5HsfffbZZ2jVqhVat26N8ePHw9/fHxkZGbh69Sp27NiBAwcOFPv9SmXs913Pnj3x4YcfYvbs2Wjbti0uXbqEefPmISAgQOfKrGHDhuHTTz/FsGHD8NFHH6FWrVrYtWsX9u7dq/O6Z8+excSJE/HKK6+gVq1asLKywoEDB3D27FmdkUKqYORby0yk7/Tp02L48OHC19dXWFlZCTs7O9GoUSPxwQcfiKSkJG0/tVotFi9eLGrXri0sLS2Fq6urGDJkiIiPj9c5X9u2bcVzzz2n9zoFV0t9/PHHBuM4c+aM6N+/v3B3dxeWlpbC09NTdOjQQaxatUqnX3x8vBg1apTw9PQUlpaWwtvbW/Tv31/cvXtX2+eHH34QdevWFZaWlgKAmD179lPz8O+//4rhw4eLatWqCUtLS+Hs7Cy6du0qdu7cqde34Gqpffv2iaFDh4oqVaoIGxsb0b17d3HlyhWdvsOHDxf+/v5651i7dq14/vnnhZ2dnbCxsRE1a9YUw4YNEydOnNDpt2vXLtG2bVthZ2cnbG1tRXBwsFi8eLH2+ZycHDFmzBjh5uYmFAqFACBiY2Of+n6FEKJv374Gr4ITQohbt26Jfv36iapVqwoHBwfRtWtXcf78eeHn5yeGDx+u7WfoaikhhPjmm29EUFCQUCqVIjg4WGzevFnvaikhhFCpVOKTTz4RDRo0EEqlUtjb24u6deuK119/XS+XTyq4WurevXtF9jMm16mpqeLll18WVapU0eaxwKNHj8QHH3wgatWqJaysrISLi4vo0KGDiIqK0vYBIN544w29134yX0Lkfy+MGjVK+Pj4CEtLS+Hm5iZatGihc5VdQV5/+umnIt/b4wqLQQghfvrpJ4P/T8Z83+Xk5Ihp06YJHx8foVQqRePGjcUvv/xi8P+z4HNjb28vHBwcRL9+/URUVJTO1VJ3794VI0aMEHXr1hV2dnbC3t5e1K9fX3z66aciLy/P6PdL5YtCiCLGmInIpPTt2xfx8fFG7UNFRFRRcc0NUSUQFxeHTZs24eDBgwgLC5M7HCKiUsXihqgSWLt2LcaNG4cOHTro3XWWiMjUcFqKiIiITIqsIzd//PEHevXqBW9vbygUCvzyyy9PPebw4cMIDQ2FUqlEjRo1eA8CIiIi0iFrcZOZmYkGDRpoLyN9mtjYWHTv3h2tW7dGdHQ03n33XUyaNAk///xzKUdKREREFUW5mZZSKBTYtm0bXnzxxUL7vPPOO9i+fbvOLbbHjRuHM2fO6N3AiYiIiCqnCnUTv7///hudO3fWaevSpQvWrFkDlUqlswFigZycHJ07k2o0GqSmpsLFxaXUbiVOREREJUsIgYyMDKP2V6tQxU1iYqLeRmgeHh7Iy8tDcnKywU3dFi5ciLlz55ZViERERFSK4uPjn7oHYYUqbgD9jdsKZtUKG4WZOXMmwsPDtY/T0tK0Oy+X9G6vKpUKBw8eRPv27Q2OIpEu5ks65kwa5ks65kwa5kuaZ8lXRkYGAgICjPrdXaGKG09PT70dXZOSkmBhYVHoBm/W1tYGd9t1dnbW21vmWalUKtja2sLFxYUfciMwX9IxZ9IwX9IxZ9IwX9I8S74K+huzpKRC3cQvLCwMkZGROm379u1DkyZN+KEiIiIiADIXNw8fPsTp06dx+vRpAPmXep8+fRpxcXEA8qeUhg0bpu0/btw43Lx5E+Hh4bhw4QLWrl2LNWvWYNq0aXKET0REROWQrNNSJ06cQPv27bWPC9bGDB8+HOvXr0dCQoK20AGAgIAA7Nq1C2+99Ra+/PJLeHt7Y8WKFejXr1+Zx05ERETlk6zFTbt27VDUbXbWr1+v19a2bVucOnWqFKMiIiKiiqxCrbkhIiIiehoWN0RERGRSWNwQERGRSWFxQ0RERCaFxQ0RERGZFBY3REREZFJY3BAREZFJYXFDREREJoXFDREREZkUFjdERERkUljcEBERkUlhcUNEREQmhcUNERERmRQWN0RERGRSWNwQERGRSWFxQ0RERCaFxQ0RERGZFBY3REREZFJY3BAREZFJYXFDREREJoXFDREREZkUFjdERERkUljcEBERkUlhcUNEREQmhcUNERERmRQWN0RERGRSWNwQERGRSWFxQ0RERCaFxQ0RERGZFBY3REREZFJY3BAREZFJYXFDREREJoXFDREREZkUFjdERERkUljcEBERkUlhcUNEREQmhcUNERERmRQWN0RERGRSWNwQERGRSWFxQ0RERCaFxQ0RERGZFBY3REREZFJY3BAREZFJYXFDREREJoXFDREREZkUFjdERERkUljcEBERkUmxkDsAIiIiMg1qjcCx2FQkZWTD3UGJZgHOMDdTlHkcLG6IiIjome05n4C5O2KQkJatbfNyUmJ2r2B0DfEq01g4LUVERETPZM/5BIzfeEqnsAGAxLRsjN94CnvOJ5RpPCxuiIiIqNjUGoG5O2IgDDxX0DZ3RwzUGkM9SgeLGyIiIpIsW6VGTp4ax2JT9UZsHicAJKRl41hsapnFxjU3REREZFBalgrHb6RCpdagW73/1s2MWn8cBy4mIeLVxshVa4w6V1JGNgDHUopUF0duiIiIKhkhBNKyVDpt/3fkOkavP46/riZr264nP8SYDSfw4W8xOn1trcwBAHfS8q+KMoax/UoCR26IiIhM1L930nApMQP1qzkh0N0BABBzJx19V/4FFzsrRM3sqO17Ov4B9l9MQlhNF7QMdAUAVKtqixAfR/g620IIAYUi/7LuWT2D8WGfEFSxtYRG5F8VlZiWbXDdjQKAp1P+ZeEadV5pv2UALG6IiIgqnEe5amiEgJ11/q/xhLRHWLz7IrJVGqwaGqrtt/LQNew8m4D3ewRpixtXByvk5Glw72EO8tQaWJjnT+K8HFoNzWu44PkAZ+3xbg7W+O3N1nqv7+H43yiMuQKY3SsY4zeeggLQKXAK7nAzu1cwzM0U0KhL5v0/DYsbIiKicigrNw9/XklGamYuBjbz1ba/s+UsNp+Ix/s9gjCmdQ0AgLlCgV9O34GZAlCpNbD8X8HSoJoTHmTlws3BWnu8m701jkxvD08npbawAYB2ddyLHWvXEC9EDGmsd58bT5nuc8PihoiIqAxpNAIpmboFx4/H47H7fAJ6N/RG30bVAAAZ2Xl47duTMFMA/UKraQuWKraWAIC76f8VEa721pjRrS58qthAPDZ08lqbmnitTU2d11coFKjubFvi76triBc6BXvyDsVERESlSc7tAC4lZuDMrQcIdLdHY9+qAIDkhzlosfAA1ELg0oddtSMn1+49xMFL9+DvaqctbtzsrdHYtwo8HJXIylXDySa/7/h2NTGhfSCcbCy1r2VmpsC4tjUhN3MzBcJqusgdBosbIiIyTaW1HUBmTh7y1AJO/xtByVEDU348i7vpOdj0WnNtwbL11C189cd1jGzpry1unG2ttOe59zAHXk42AIAuIZ7wc7FD/WpO2ufNzBTYOqGl3utXeewcZBiLGyIiMjkF2wE8efVOwXYAEUMaF1ng5Kk1iIy5i9sPHmFEC39twbJ03yV8fuAqRrUMwAe9ggEAlmbAvpi7UKkFEtOzUa1q/pRPsLcjWtdyRQ1XO+15zcwU+GN6e7jaW+msd2nsW1VbANGzY3FDREQmxdjtADoFe8LcTIHd5xKw6Xg8wmq6aKd2zBQKTNoUDZVaoGuIp7ZgKVgnk5KZoz2nmQL4oEcQnO2VOqMqfRr6oE9DH70YPJ3K7n4vlRWLGyIiMilP2w4A+G87gLCaLkjKyMHhy/egtPxvJMXMTIGOdT1gbq7QWaDbr3E19G3kAwelpc75BjatBktL3TaSj+x3KF65ciUCAgKgVCoRGhqKI0eOFNn/u+++Q4MGDWBrawsvLy+MHDkSKSkpZRQtERGVN0II3EzJRLYq/yYq+bf5f7qCfi0DXbGkX32Mbxeo8/yqoaH4cnBjnSuL7Kwt9AobKn9kLW42b96MKVOm4L333kN0dDRat26Nbt26IS4uzmD/P//8E8OGDcPo0aPx77//4qeffsLx48cxZsyYMo6ciIjkkpmje5fbbp8dQduPD+FM/AMAxt/mv6BfoLs9+jetjobVq5RkmCQjWYubZcuWYfTo0RgzZgyCgoKwfPlyVK9eHREREQb7Hz16FP7+/pg0aRICAgLQqlUrvP766zhx4kQZR05ERGVBPDYndPLmfTy/4He8vOpvnT6+zrawMjfD7QePAADNApzh6ahEYRd8K5B/1VSzx+7ES6ZFtjU3ubm5OHnyJGbMmKHT3rlzZ0RFRRk8pkWLFnjvvfewa9cudOvWDUlJSdiyZQt69OhR6Ovk5OQgJ+e/hV/p6ekAAJVKBZVKVdhhxVJwvpI+r6livqRjzqRhvqQrLzlbeeg6tkbfwfi2AejXOH9RrpudBe6m5yA1MxcPH+XA2iL/7/O5verC8ZV6sLIw08b9fvc6eHPTmUK3A3ivWx1o1HnPvB1AeclXRfEs+ZJyjEI8XhaXoTt37sDHxwd//fUXWrRooW1fsGABvvnmG1y6dMngcVu2bMHIkSORnZ2NvLw89O7dG1u2bCl0IdecOXMwd+5cvfbvv/8etrYlf4dGIiIyXlYe8MsNM9x9pMDkEDUK7q/36w0zHEgwQ0sPDfrX0AAAhABiMwAfO8Da/OnnPpOiwNYbZniQ+98YThUrgZf8NWjgIsuvPnoGWVlZGDx4MNLS0uDo6FhkX9mvlirYYbTA47uOPikmJgaTJk3CBx98gC5duiAhIQFvv/02xo0bhzVr1hg8ZubMmQgPD9c+Tk9PR/Xq1dG5c+enJkcqlUqFyMhIdOrUiavmjcB8ScecScN8SVeaOTsV9wC/nU1AbQ8HDGyafxfePLUGcz86gGyVBkHN2qKmW/49YWolPcSQ9GzU83bSbjcgVXcA0zUCJ27eR1JGDtwdrNHEr2qJ3qGYnzFpniVfBTMvxpCtuHF1dYW5uTkSExN12pOSkuDh4WHwmIULF6Jly5Z4++23AQD169eHnZ0dWrdujfnz58PLS/+GTNbW1rC2ttZrt7S0LLUPYmme2xQxX9IxZ9IwX8ZRawROxabiZLICLrcyEBboXuxCYPe5BETHP8DrbWrAxT7/Z/CVe1n49p94tK7liqEtAgAAlpbA+z2C4eZgjWou9rC0zP+1FOxTFcH6t4iRzBJAq9qGf6eUJH7GpClOvqT0l624sbKyQmhoKCIjI9G3b19te2RkJPr06WPwmKysLFhY6IZsbp4/NinT7BoRkUnQ3arAHBuunDBqq4L0bBWOx6YiW6VBj/r/9VsaeRlXkx6ieQ1ndKibX1w0r+GC0a0C9BbyDmnuVyrviSovWaelwsPDMXToUDRp0gRhYWFYvXo14uLiMG7cOAD5U0q3b9/Ghg0bAAC9evXC2LFjERERoZ2WmjJlCpo1awZvb2853woRUYVl7FYF6dkqnLuVhgBXO3hXyd8T6Uz8A4z+5gR8nW11ipte9b21m1UWCHS3x6yewWXxlqiSk7W4GTBgAFJSUjBv3jwkJCQgJCQEu3btgp9ffhWfkJCgc8+bESNGICMjA1988QWmTp2KKlWqoEOHDli8eLFcb4GIqEJ72lYFCvy3VcFbm05j/8UkzO4VjJEt86eV6vtUQaC7PRpUq4I8tUa7X9LkF2qV2XsgepLsC4onTJiACRMmGHxu/fr1em1vvvkm3nzzzVKOioiocnjaVgUC/21V0KB6FVxOyoDZYxd9ONla4vfwtmUQKZHxZC9uiIhIPlK2KpjYPhCTOnJEhso/2feWIiIi+UjZqsCsBC+hJipNLG6IiCqxBtWdUFTNwq0KqCJicUNEVInZWllgepe6AKC3F1PB49m9gkv0xndEpY3FDRFRJZOtUuPavYfax+Pa1cSqIY3h6aQ7ReXppNReBk5UkXBBMRFRJXI/MxdjNpxAXGoWfnmjJXz+d7+ariFe6BTsib+vJmHfkX/QufXzz3SHYiI5ceSGiKgSsTBXIDMnD9kqNRIePNJ5ztxMgecDnBHqKvB8gDMLG6qwOHJDRFSJOCgtsXZEU2Tm5KGWh4Pc4RCVChY3REQmblv0LSgtzNGtXv7amYKtE4hMFYsbIiITduhSEt7afAbWFmao5WGPQHeO1pDpY3FDRGTCWtdyQ8e67qjt6YAarvZyh0NUJljcEBGZmIc5ebCzModCoYC5mQJfDQ3VbmhJVBnw005EZEJuJGei1+d/YuWha9o2FjZU2fATT0RkQv6+noLY5Ex8/08cMnPy5A6HSBacliIiMiGDmvkiR6VG93pesLPmj3iqnDhyQ0RUgQkh8PPJW8jJU2vbRrQMgLujcbt9E5kiFjdERBXY3B0xmPrTGcz8+RyEEHKHQ1QusLghIqrAOtR1h5WFGRr5VYVCwe0SiACuuSEiqnCEENpCpk1tNxyZ3h4enIYi0uLIDRFRBXIq7j5eXvU3UjNztW0sbIh0sbghIqog1BqBd7acxcmb9/Hx3ktyh0NUbrG4ISKqIMzNFIgY0hgvNvTG+z2C5A6HqNxicUNEVI6p1BpcvpuhfRzo7oDlAxvxHjZERWBxQ0RUTmVkqzBq/XG8HBGFq0kZTz+AiACwuCEiKrcszc2QlauGSi1w+0G23OEQVRgc1yQiKqeUlub4elgT3HnwCCE+TnKHQ1RhsLghIipH9v6biLQsFfo3rQ4AcLazgrOdlcxREVUsLG6IiMqJkzfvY9zGkzBTKFDb0wENq1eROySiConFDRFROdHYtwpebOgDO2tzhHg7yh0OUYXF4oaISEaZOXlQWprD3EwBhUKBj1+ur/03ERUPr5YiIpJJQtoj9IuIwqLdF7RtFuZmLGyInhGLGyIimUTHPcDFxAxsi76DlIc5codDZDI4LUVEJJPu9byw8KV6aF3LFS721nKHQ2QyOHJDRFSGfom+jcycPO3jQc18Ua2qrYwREZkeFjdERGVkWeRlTNl8GpM3RUOtEXKHQ2SyWNwQEZWRdnXcoLQ0Q6ifM8y4Zpio1HDNDRFRKRJCaK9+auxbFYffbg8PR6XMURGZNskjN7GxsaURBxGRyYm5k44XV0bhzoNH2jYWNkSlT3JxExgYiPbt22Pjxo3IzuYutUREhggh8P4v53Am/gE+2nnh6QcQUYmRXNycOXMGjRo1wtSpU+Hp6YnXX38dx44dK43YiIgqLIVCgRWDGqFnfS8s6FtP7nCIKhXJxU1ISAiWLVuG27dvY926dUhMTESrVq3w3HPPYdmyZbh3715pxElEVO6pNQIXEtK1j6tVtcUXgxvDydZSxqiIKp9iXy1lYWGBvn374scff8TixYtx7do1TJs2DdWqVcOwYcOQkJBQknESEZVr2So1Jnx3En1X/oUz8Q/kDoeoUit2cXPixAlMmDABXl5eWLZsGaZNm4Zr167hwIEDuH37Nvr06VOScRIRlWsWZgrk5Gmg0UBnATERlT3Jl4IvW7YM69atw6VLl9C9e3ds2LAB3bt3h5lZfp0UEBCAr776CnXr1i3xYImIyisLczN8MbgxrtzNQCPfqnKHQ1SpSS5uIiIiMGrUKIwcORKenp4G+/j6+mLNmjXPHBwRUXn255VkXEnKwMiWAQAAe2sLFjZE5YDk4ubKlStP7WNlZYXhw4cXKyAioorgyt0MjFh3DHkagUB3e7Su5SZ3SET0P5KLm3Xr1sHe3h6vvPKKTvtPP/2ErKwsFjVEVCnU8nDAkOZ+eJCVi2YBznKHQ0SPkbygeNGiRXB1ddVrd3d3x4IFC0okKCKi8ihbpUZunkb7eFbPYHw6oCGsLcxljIqIniS5uLl58yYCAgL02v38/BAXF1ciQRERlTfJD3Mw6OujeG/bOQiRv6O3uZlCu28UEZUfkosbd3d3nD17Vq/9zJkzcHFxKZGgiIjKm4sJGTh7Kw37Yu7i1n1e6k1UnkleczNw4EBMmjQJDg4OaNOmDQDg8OHDmDx5MgYOHFjiARIRlQetarli6SsNUK+aE6o728odDhEVQXJxM3/+fNy8eRMdO3aEhUX+4RqNBsOGDeOaGyIyKTvPJqBFTRdUtbMCALzYyEfmiIjIGJKLGysrK2zevBkffvghzpw5AxsbG9SrVw9+fn6lER8RkSzW/BmLD3+LQbMAZ2wc/TysLIp9Q3ciKmOSi5sCtWvXRu3atUsyFiKicqNVoCscrC3Q1L8qLMy4aJioIilWcXPr1i1s374dcXFxyM3N1Xlu2bJlJRIYEVFZE0Jor36q4+mA/VPbwt1RKXNURCSV5OJm//796N27NwICAnDp0iWEhITgxo0bEEKgcePGpREjEVGJU2sEjsWmIikjG+4OSrg5WGPqT2ewrH8D1HSzBwAWNkQVlOTiZubMmZg6dSrmzZsHBwcH/Pzzz3B3d8err76Krl27lkaMREQlas/5BMzdEYOEtGxtm7WFGXLyNPjg1/P4bkxzGaMjomcleYXchQsXtFssWFhY4NGjR7C3t8e8efOwePHiEg+QiKgk7TmfgPEbT+kUNgCQ8787D/duwCuiiCo6ycWNnZ0dcnJyAADe3t64du2a9rnk5OSSi4yIqISpNQJzd8RAFPK8AsDy3y9DrSmsBxFVBJKnpZo3b46//voLwcHB6NGjB6ZOnYpz585h69ataN6cQ7lEVH4di03VG7F5nACQkJaNY7GpCKvJO64TVVSSi5tly5bh4cOHAIA5c+bg4cOH2Lx5MwIDA/Hpp5+WeIBERCUlKaPwwqY4/YiofJJU3KjVasTHx6N+/foAAFtbW6xcubJUAiMiKmnuDsZd/WRsPyIqnyStuTE3N0eXLl3w4MGDUgqHiKj0NAtwhpeTEoXdkk8BwMtJiWYBzmUZFhGVMMkLiuvVq4fr16+XWAArV65EQEAAlEolQkNDceTIkSL75+Tk4L333oOfnx+sra1Rs2ZNrF27tsTiISLTZW6mwKwewQCgV+AUPJ7dKxjmvCMxUYUmec3NRx99hGnTpuHDDz9EaGgo7OzsdJ53dHQ0+lybN2/GlClTsHLlSrRs2RJfffUVunXrhpiYGPj6+ho8pn///rh79y7WrFmDwMBAJCUlIS8vT+rbIKJKKjkzB9WdbZGRrcL9LJW23dNJidm9gtE1xEvG6IioJEgubgpu1Ne7d2/tbcqB/25brlarjT7XsmXLMHr0aIwZMwYAsHz5cuzduxcRERFYuHChXv89e/bg8OHDuH79Opyd84eN/f39pb4FIqrEfjgWj7jULMzuFYy6no7aOxQ3C3DmiA2RiZBc3Bw8eLBEXjg3NxcnT57EjBkzdNo7d+6MqKgog8ds374dTZo0wZIlS/Dtt9/Czs4OvXv3xocffggbGxuDx+Tk5GjvywMA6enpAACVSgWVSmXwmOIqOF9Jn9dUMV/SMWfSGMrX+uGN8dPJ23ixgSfsrS0A5I82a9R50Bj/t5nJ4mdMGuZLmmfJl5RjJBc3bdu2lXqIQcnJyVCr1fDw8NBp9/DwQGJiosFjrl+/jj///BNKpRLbtm1DcnIyJkyYgNTU1ELX3SxcuBBz587Va9+3bx9sbW2f/Y0YEBkZWSrnNVXMl3TMmTRP5qs6gD/2X5AnmAqCnzFpmC9pipOvrKwso/tKLm7++OOPIp9v06aNpPM9PrUF6O7K+ySNRgOFQoHvvvsOTk5OAPKntl5++WV8+eWXBkdvZs6cifDwcO3j9PR0VK9eHZ07d5a0PsgYKpUKkZGR6NSpEywtLUv03KaI+ZKOOZPm8XxZWFgU+rOF/sPPmDTMlzTPkq+CmRdjSC5u2rVrp9f2+A8MY9fcuLq6wtzcXG+UJikpSW80p4CXlxd8fHy0hQ0ABAUFQQiBW7duoVatWnrHWFtbw9raWq/d0tKy1D6IpXluU8R8ScecSWNpaYn5uy7hwSMV3uwQiEB3B7lDKvf4GZOG+ZKmOPmS0l/ypeD379/X+UpKSsKePXvQtGlT7Nu3z+jzWFlZITQ0VG9oKjIyEi1atDB4TMuWLXHnzh3tHZIB4PLlyzAzM0O1atWkvhUiqiQysvOw+UQ8fj19B8kPc+UOh4hKmeSRm8dHTQp06tQJ1tbWeOutt3Dy5EmjzxUeHo6hQ4eiSZMmCAsLw+rVqxEXF4dx48YByJ9Sun37NjZs2AAAGDx4MD788EOMHDkSc+fORXJyMt5++22MGjWq0AXFREQOSgtsGdcCu88n4HneoI/I5Ekubgrj5uaGS5cuSTpmwIABSElJwbx585CQkICQkBDs2rULfn5+AICEhATExcVp+9vb2yMyMhJvvvkmmjRpAhcXF/Tv3x/z588vqbdBRCYqxMcJIT76f5wRkemRXNycPXtW57EQAgkJCVi0aBEaNGggOYAJEyZgwoQJBp9bv369XlvdunW5Kp2IiIgKJbm4adiwIRQKBYQQOu3NmzfnNghEVO6suWSGa8prGN26JpxsueCTqDKQXNzExsbqPDYzM4ObmxuUSu6iS0Tly9lbaTibaoYLf1zHkBb+AFjcEFUGkoubgvUwRETlXZCXA4bXUsPFrw7cHfgHGFFlIflS8EmTJmHFihV67V988QWmTJlSEjEREZUIS3MzNHYVGN+2htyhEFEZklzc/Pzzz2jZsqVee4sWLbBly5YSCYqIiIiouCRPS6WkpBi8142joyOSk5NLJCgiomeRrVJj3MaT6F3fExBP709EpkXyyE1gYCD27Nmj1757927UqMGhXyKS36+nb+PQpXv4ZN8VuUMhIhlIHrkJDw/HxIkTce/ePXTo0AEAsH//fixduhTLly8v6fiIiCTrUNcDb72QAxc7C5gnnX36AURkUiQXN6NGjUJOTg4++ugjfPjhhwAAf39/REREYNiwYSUeIBGRVG4O1pj8Qi2oVCrs2sXihqiyKdb2C+PHj8f48eNx79492NjYwN7evqTjIiIiIioWyWtuYmNjceVK/jy2m5ubtrC5cuUKbty4UaLBERFJcTMlE+GbT+P87TS5QyEiGUkubkaMGIGoqCi99n/++QcjRowoiZiIiIplfdQNbI2+jY/3StvEl4hMi+TiJjo62uB9bpo3b47Tp0+XRExERMXSt5EP+jT0xpjWAXKHQkQykrzmRqFQICMjQ689LS0NarW6RIIiIiqO+tWq4LOBjeQOg4hkJnnkpnXr1li4cKFOIaNWq7Fw4UK0atWqRIMjIiIikkryyM2SJUvQpk0b1KlTB61btwYAHDlyBOnp6Thw4ECJB0hE9DR/XknG6fj7GPy8H5ztrOQOh4hkJnnkJjg4GGfPnkX//v2RlJSEjIwMDBs2DBcvXkRISEhpxEhEVKSVh67ik32X8dUf1+QOhYjKgWLd58bb2xsLFizQaUtJScHy5cu5MzgRlSkhBPo3qY6sXDWGNveTOxwiKgckj9w8TgiBvXv3on///vD29sZHH31UUnERERlFoVDgxUY++OWNlqhW1VbucIioHChWcXPjxg188MEH8PPzQ/fu3WFtbY2dO3ciMTGxpOMjIiIiksTo4iYnJwc//PADOnbsiKCgIJw/fx7Lli2DmZkZZs6ciRdeeAHm5ualGSsRkY5fom9j17kE5Kk1codCROWI0WtufHx8EBwcjCFDhmDLli2oWrUqAGDQoEGlFhwRUWFUag0W7r6Au+k5WDGoEXo38JY7JCIqJ4weuVGr1VAoFFAoFByhISLZ5eZpMKBJddT1dEDX5zzlDoeIyhGji5uEhAS89tpr+OGHH+Dp6Yl+/fph27ZtUCgUpRkfEZFBdtYWCO9cB7snt4aVxTNdG0FEJsbonwhKpRKvvvoqDhw4gHPnziEoKAiTJk1CXl4ePvroI0RGRnL7BSIqc/wDi4ieVKw/d2rWrIn58+fj5s2b2LlzJ3JyctCzZ094eHiUdHxERHq+/ycOFxLS5Q6DiMqpYt3Er4CZmRm6deuGbt264d69e/j2229LKi4iIoMS0h5h1q/nodYIHJzWDgGudnKHRETlzDMVN49zc3NDeHh4SZ2OiMggVZ5A1xBPPMjKZWFDRAaVWHFDRFQWfF1s8eXgxry3DREVipcYEFGFZGHOH19EZBh/OhBRhSCEwHf/3MSDrFy5QyGico7FDRFVCH9dTcF7287jhWWHkZvHKSkiKpzkNTdqtRrr16/H/v37kZSUBI1G94fMgQMHSiw4IqLHBXk5opl/Vd60j4iKJLm4mTx5MtavX48ePXogJCSEN9AiojLRqpYrdk1qhRyO2hDRU0gubjZt2oQff/wR3bt3L414iIgKpVAooLTk3nZEVDTJY7tWVlYIDAwsjViIiPSkZ6uw799EqDVC7lCIqIKQXNxMnToVn332GYTgDxoiKn0/Ho/Ha9+exNgNJ+QOhYgqCMnTUn/++ScOHjyI3bt347nnnoOlpaXO81u3bi2x4IiIFAoFnGws8UIQ964jIuNILm6qVKmCvn37lkYsRER6RrcKwOBmvuC1C0RkLMnFzbp160ojDiKiQtlYcRExERmv2HtL3bt3D5cuXYJCoUDt2rXh5uZWknERUSUXl5KFnDw1ank4yB0KEVUwkhcUZ2ZmYtSoUfDy8kKbNm3QunVreHt7Y/To0cjKyiqNGImoElpx4Ao6ffoHvjx4Ve5QiKiCkVzchIeH4/Dhw9ixYwcePHiABw8e4Ndff8Xhw4cxderU0oiRiCoZIQRy8zQwUwAtarrIHQ4RVTCSp6V+/vlnbNmyBe3atdO2de/eHTY2Nujfvz8iIiJKMj4iqoQUCgVWDGqEd7sHwdNJKXc4RFTBSB65ycrKgoeH/iWZ7u7unJYiohLFwoaIikNycRMWFobZs2cjOztb2/bo0SPMnTsXYWFhJRocEVU+V+5mIO2RSu4wiKgCkzwt9dlnn6Fr166oVq0aGjRoAIVCgdOnT0OpVGLv3r2lESMRVRJCCLz142lcv5eJiCGhaFubV2ESkXSSi5uQkBBcuXIFGzduxMWLFyGEwMCBA/Hqq6/CxsamNGIkokrifpYKuXkaqDUC9Xyc5A6HiCqoYt3nxsbGBmPHji3pWIioknO2s8LeKW1w7V4mnO2s5A6HiCooo4qb7du3o1u3brC0tMT27duL7Nu7d+8SCYyIKieFQoFAd3u5wyCiCsyo4ubFF19EYmIi3N3d8eKLLxbaT6FQQK1Wl1RsRFSJXLv3EAEudjAz4yZSRPRsjCpuNBqNwX8TET0LtUbgWGwqbt3Pwuxfz8PdUYmNY55Htaq2codGRBWY5EvBN2zYgJycHL323NxcbNiwoUSCIiLTt+d8AlotPoBBXx/F21vOIkulQfz9RzgbnyZ3aERUwUkubkaOHIm0NP0fPhkZGRg5cmSJBEVEpm3P+QSM33gKCWnZOu1qjcAb35/CnvMJMkVGRKZAcnEjhIBCoT8nfuvWLTg58dJNIiqaWiMwd0cMRBF95u6IgVpTVA8iosIZfSl4o0aNoFAooFAo0LFjR1hY/HeoWq1GbGwsunbtWipBEpHpOBabqjdi8zgBICEtG8diUxHGTTOJqBiMLm4KrpI6ffo0unTpAnv7/y7VtLKygr+/P/r161fiARKRaUnKKLywKU4/IqInGV3czJ49GwDg7++PAQMGQKnkhnZEJJ27g3E/O4ztR0T0JMlrboYPH87ChoiKrVmAM7yclCjsbjYKAF5OSjQLcC7LsIjIhEgubtRqNT755BM0a9YMnp6ecHZ21vkiIiqKuZkCs3sFA4BegVPweHavYJjzZn5EVEySi5u5c+di2bJl6N+/P9LS0hAeHo6XXnoJZmZmmDNnTimESESm5H5mLv68mowlL9eHp5PuKLCnkxIRQxqja4iXTNERkSmQvHHmd999h6+//ho9evTA3LlzMWjQINSsWRP169fH0aNHMWnSpNKIk4hMxIc7Y7D11G1crfEQf77TAcdiU5GUkQ13h/ypKI7YENGzklzcJCYmol69egAAe3t77Q39evbsiVmzZpVsdERkcoaF+eNCQgbe6VoX5mYKXu5NRCVO8rRUtWrVkJCQf/fQwMBA7Nu3DwBw/PhxWFtbSw5g5cqVCAgIgFKpRGhoKI4cOWLUcX/99RcsLCzQsGFDya9JRPJpWL0Kdr7ZCo18q8odChGZKMnFTd++fbF//34AwOTJkzFr1izUqlULw4YNw6hRoySda/PmzZgyZQree+89REdHo3Xr1ujWrRvi4uKKPC4tLQ3Dhg1Dx44dpYZPRDJ5lKvW/ps7fxNRaZI8LbVo0SLtv19++WVUq1YNUVFRCAwMRO/evSWda9myZRg9ejTGjBkDAFi+fDn27t2LiIgILFy4sNDjXn/9dQwePBjm5ub45ZdfpL4FIipjJ2+m4rUNJzGrZzBebOQjdzhEZOIkFzdPat68OZo3by75uNzcXJw8eRIzZszQae/cuTOioqIKPW7dunW4du0aNm7ciPnz5z/1dXJycnR2MU9PTwcAqFQqqFQqyXEXpeB8JX1eU8V8SVdRc7bmyHWkZObiyJUk9AhxL7PXraj5khNzJg3zJc2z5EvKMUYVN9u3bzf6hMaO3iQnJ0OtVsPDw0On3cPDA4mJiQaPuXLlCmbMmIEjR47o7G1VlIULF2Lu3Ll67fv27YOtra1R55AqMjKyVM5rqpgv6Spazl6wAyz9FGhiHoddu4qedi4NFS1f5QFzJg3zJU1x8pWVlWV0X6MqhIJ9pQooFAoIIfTagPyb/Enx5A7jhe06rlarMXjwYMydOxe1a9c2+vwzZ85EeHi49nF6ejqqV6+Ozp07w9HRUVKsT6NSqRAZGYlOnTrB0tKyRM9tipgv6SpyznrJ8JoVOV9yYc6kYb6keZZ8Fcy8GMOo4kaj0Wj//fvvv+Odd97BggULEBYWBoVCgaioKLz//vtYsGCB0S/s6uoKc3NzvVGapKQkvdEcAMjIyMCJEycQHR2NiRMnauMSQsDCwgL79u1Dhw4d9I6ztrY2eBWXpaVlqX0QS/Pcpoj5kq4i5CxPrcH+i0noHOxh8A+WslQR8lXeMGfSMF/SFCdfUvpLXnMzZcoUrFq1Cq1atdK2denSBba2tnjttddw4cIFo85jZWWF0NBQREZGom/fvtr2yMhI9OnTR6+/o6Mjzp07p9O2cuVKHDhwAFu2bEFAQIDUt0JEpWjdXzfw0a4L6FnfC18Mbix3OERUiUgubq5duwYnJye9dicnJ9y4cUPSucLDwzF06FA0adIEYWFhWL16NeLi4jBu3DgA+VNKt2/fxoYNG2BmZoaQkBCd493d3aFUKvXaiUh+ZmYKWFmYoXUtV7lDIaJKRnJx07RpU0yZMgUbN26El1f+/i+JiYmYOnUqmjVrJulcAwYMQEpKCubNm4eEhASEhIRg165d8PPzAwAkJCQ89Z43RFQ+jW4VgC7PecCnio3coRBRJSO5uFm7di369u0LPz8/+Pr6AgDi4uJQu3btYt1zZsKECZgwYYLB59avX1/ksXPmzOFmnUTlWLWqpXNFIhFRUSQXN4GBgTh79iwiIyNx8eJFCCEQHByMF154QfZFg0Qkr7vp2Zj96794t3sQfF1Y2BCRPIp1Ez+FQoHOnTujc+fOJR0PEVVg83dewJ5/E/HgUS42vRYmdzhEVEkZVdysWLECr732GpRKJVasWFFk30mTJpVIYERU8UztVBsPsnLxbvcguUMhokrMqOLm008/xauvvgqlUolPP/200H4KhYLFDVEl5u9qh29HPy93GERUyRlV3MTGxhr8NxERAKQ8zIGLvf7NMomI5GAmdwBEVLEduXIPLRcfwP8duS53KEREAIwcuXl8b6anWbZsWbGDIaKKZ8eZO8hWaXDr/iO5QyEiAmBkcRMdHW3UyXgpOFHls7hffYTVdEGnYE+5QyEiAmBkcXPw4MHSjoOIKiiFQoG+jarJHQYRkRbX3BCRZLl5Gmw8ehMqtUbuUIiI9BTrJn7Hjx/HTz/9hLi4OOTm5uo8t3Xr1hIJjIjKr5WHrmL571cQGXMX34yStqccEVFpkzxys2nTJrRs2RIxMTHYtm0bVCoVYmJicODAAYO7hROR6fFzsYWTjSVeDuV0FBGVP5JHbhYsWIBPP/0Ub7zxBhwcHPDZZ58hICAAr7/+unaXcCIybX0bVUOHOh5wtCnW4C8RUamSPHJz7do19OjRAwBgbW2NzMxMKBQKvPXWW1i9enWJB0hE5ZOTrSWvkCSicklycePs7IyMjAwAgI+PD86fPw8AePDgAbKysko2OiIqN+JTs9AvIgpnbz2QOxQioiJJLm5at26NyMhIAED//v0xefJkjB07FoMGDULHjh1LPEAiKh8W7bmIkzfvY9Hui3KHQkRUJKMnzE+fPo2GDRviiy++QHZ2NgBg5syZsLS0xJ9//omXXnoJs2bNKrVAiUhec3s/B2sLM7zZoZbcoRARFcno4qZx48Zo1KgRxowZg8GDBwMAzMzMMH36dEyfPr3UAiSi8sHV3hrL+jeUOwwioqcyelrqr7/+QuPGjTFjxgx4eXlhyJAhvHMxUSUQm5wpdwhERJIYXdyEhYXh66+/RmJiIiIiInDr1i288MILqFmzJj766CPcunWrNOMkIhns/TcRHZcewsLdF+QOhYjIaJIXFNvY2GD48OE4dOgQLl++jEGDBuGrr75CQEAAunfvXhoxEpFMjsemQiMAc17yTUQVyDPdgatmzZqYMWMGqlevjnfffRd79+4tqbiIqBx4v2cw2tVxRxP/qnKHQkRktGIXN4cPH8batWvx888/w9zcHP3798fo0aNLMjYiKgda1XKVOwQiIkkkFTfx8fFYv3491q9fj9jYWLRo0QKff/45+vfvDzs7u9KKkYjK0KNcNb764xrGtq4BO2tur0BEFY/RP7k6deqEgwcPws3NDcOGDcOoUaNQp06d0oyNiGTw6e+XsfqP64i6moIfx4XJHQ4RkWRGFzc2Njb4+eef0bNnT5ibm5dmTEQko1aBrth5NgHj2tWQOxQiomIxurjZvn17acZBROVEm9puODCtLawt+EcMEVVMki8FJyLTpNYI7b9Z2BBRRcbihohwNSkDLyw7jEOXkuQOhYjombG4ISKs2H8VscmZWB91A0KIpx9ARFSO8TpPIsKifvXg5aTEsBb+UPBuxERUwbG4ISLYWllgZvcgucMgIioRnJYiqqSEEDh5877cYRARlTgWN0SV1C+nb6NfRBTe/ukM19kQkUlhcUNUSd2+/whmCsDf1Y7rbIjIpHDNDVElNbFDLbSv647aHg5yh0JEVKJY3BBVYs95O8kdAhFRieO0FFElkpGtwvu/nMO9jBy5QyEiKjUsbogqkcV7LmLj0TiM2XCCi4iJyGSxuCGqRAY29cVz3o54p2sdLiImIpPFNTdElUiIjxN2TGwFMzMWNkRkujhyQ1QJZKvU2n+zsCEiU8fihsjEnb+dhhaLDuDHE/FcZ0NElQKLGyITtz7qBlIzc3H40j2usyGiSoFrbohM3KKX6qGupwP6NPSROxQiojLB4obIxFmYm2FM6xpyh0FEVGY4LUVkgjQagb3/JnKNDRFVSixuiEzQ98fi8Pq3JzGWN+sjokqIxQ2RCRIAlJZmaBnoykXERFTpcM0NkQka2twP7eu4wcvJRu5QiIjKHIsbIhNVraqt3CEQEcmC01JEJiI1Mxfjvj2J2ORMuUMhIpIVixsiE7Fo9wXs+TcRUzZFcxExEVVqnJYiMhFvdqiFu+k5mPJCLS4iJqJKjcUNkYmo7myLb0Y1kzsMIiLZcVqKqIJLzcyVOwQionKFxQ1RBXbiRipaLNqPLw9e5TobIqL/YXFDVIFtP3MH2SoNbiRncp0NEdH/cM0NUQU2t/dzCPWrina13eUOhYio3GBxQ1SBKRQK9GnoI3cYRETlCqeliCoYtQB+OB6P3DyN3KEQEZVLLG6IKpjDCQp8sP0ChvzfP1xETERkAIsbogqmqhVQ1dYS/UJ9uIiYiMgA2YublStXIiAgAEqlEqGhoThy5Eihfbdu3YpOnTrBzc0Njo6OCAsLw969e8swWiL5NXIV2De5Ffo3qS53KERE5ZKsxc3mzZsxZcoUvPfee4iOjkbr1q3RrVs3xMXFGez/xx9/oFOnTti1axdOnjyJ9u3bo1evXoiOji7jyInkVcXWkqM2RESFkLW4WbZsGUaPHo0xY8YgKCgIy5cvR/Xq1REREWGw//LlyzF9+nQ0bdoUtWrVwoIFC1CrVi3s2LGjjCMnKlt307PxyqoonI5/IHcoRETlnmyXgufm5uLkyZOYMWOGTnvnzp0RFRVl1Dk0Gg0yMjLg7OxcaJ+cnBzk5ORoH6enpwMAVCoVVCpVMSIvXMH5Svq8por5Mt6SPRdw/MZ9zN95ESOrM2fG4mdMOuZMGuZLmmfJl5RjZCtukpOToVar4eHhodPu4eGBxMREo86xdOlSZGZmon///oX2WbhwIebOnavXvm/fPtja2koL2kiRkZGlcl5TxXw9XagZEO9mhnYuqVAomDOpmC/pmDNpmC9pipOvrKwso/vKfhO/J9cNCCGMWkvwww8/YM6cOfj111/h7l743VlnzpyJ8PBw7eP09HRUr14dnTt3hqOjY/EDN0ClUiEyMhKdOnWCpaVliZ7bFDFf0rwC5kwq5ks65kwa5kuaZ8lXwcyLMWQrblxdXWFubq43SpOUlKQ3mvOkzZs3Y/To0fjpp5/wwgsvFNnX2toa1tbWeu2Wlpal9kEszXObIuarcDdTMuHnYqfXzpxJw3xJx5xJw3xJU5x8Sekv24JiKysrhIaG6g1NRUZGokWLFoUe98MPP2DEiBH4/vvv0aNHj9IOk0g2f1y+h3afHMLcHf/yZn1ERBLIOi0VHh6OoUOHokmTJggLC8Pq1asRFxeHcePGAcifUrp9+zY2bNgAIL+wGTZsGD777DM0b95cO+pjY2MDJycn2d4HUWk4FpsKIQAh9KdviYiocLIWNwMGDEBKSgrmzZuHhIQEhISEYNeuXfDz8wMAJCQk6Nzz5quvvkJeXh7eeOMNvPHGG9r24cOHY/369WUdPlGpmtalDsJquqBh9Spyh0JEVKHIvqB4woQJmDBhgsHnnixYDh06VPoBEZUjLQNd5Q6BiKjCkX37BSL6T06eGp/9fgUZ2bxnBhFRcbG4ISpHVh68hk9/v4zBX3PHbyKi4mJxQ1SOPB/gDF9nW7zWpgYXERMRFZPsa26I6D8tAl2x7602sLbg3x1ERMXFn6BE5YBG898UlNLSnKM2RETPgMUNkcziU7PwwrLD+D3mrtyhEBGZBBY3RDL74sBVXE/OxNdHrnMRMRFRCeCaGyKZze3zHJztrdC/SXVORxERlQAWN0QyU1qa452udeUOg4jIZHBaikgm0XH35Q6BiMgksbghksGe84nouzIKk36I5jobIqISxuKGSAZxqZkwN1OgWlUbrrMhIiphXHNDJIPX2tRE61puCHC1kzsUIiKTw+KGSCZBXo5yh0BEZJI4LUVURh7lqvHBr+eRlJ4tdyhERCaNxQ1RGVn++2Vs+Psmhq09xkXERESliMUNURl5sZEP6ldzwvSudbiImIioFHHNDVEZCfJyxC8TWsLMjIUNEVFp4sgNUSnLVqm1/2ZhQ0RU+ljcEJWiq0kZaLX4AL7/J47rbIiIygiLG6JS9E3UTSQ/zEVkTKLcoRARVRpcc0NUgtQagWOxqUjKyIa7gxKzegYjwNUOXUI8uYiYiKiMsLghKiF7zidg7o4YJKT9dx8bLyclZvcKhk8VGxkjIyKqXDgtRVQC9pxPwPiNp3QKGwBITMvG+I2nsOd8gkyRERFVPixuiJ6RWiMwd0cMDC0XLmibuyMGag0XFBMRlQUWN0TP6Fhsqt6IzeMEgIS0bByLTS27oIiIKjEWN0TPKCnDuL2ijO1HRETPhsUN0TMy9iIodwdl6QZCREQAeLUU0TP75dTtIp9XAPB0UqJZgHPZBEREVMlx5IboGX3Ytx6CvRwB5Bcyjyt4PLtXMMy59QIRUZlgcUMkUcyddGyLvqV97FPFBrsmt8aqIY3h6aQ79eTppETEkMboGuJV1mESEVVanJYikuBiYjpe/PIvAEAtdweE+Dhpn+sa4oVOwZ46dyhuFuDMERsiojLG4oZIgjoeDmhbxw0ajYC3gbsOm5spEFbTRYbIiIioAIsboqc4efM+6ldzgqW5GRQKBVYMbASlpRn3iiIiKqe45oaoCF8evIqXV0Xhs9+vaNtsrMxZ2BARlWMsboiK4OdiCyGA+1m5EILbJxARVQScliJ6Qnq2Co5KSwBAz/re8HW2Rf1qVeQNioiIjMaRG6L/yczJw7SfzuCllVF4lKvWtrOwISKqWFjcEP1PtkqNPy7fw/V7D/HX1WS5wyEiomLitBTR/7jYW2PFoEZQAHi+Bi/nJiKqqDhyQ5XWvYwcjFp/HP9cT9G2Na/hwsKGiKiCY3FDldaXB6/iwMUkzNx6DmoNr4QiIjIVnJaiSuvtLnWQkPYIUzvX4RYJREQmhMUNmRy1Rhjc3yk2ORP7L9zFmNY1AAB21hb4amgTmaMlIqKSxuKGTMqe8wmYuyMGCWnZ2jYvJyXe6lQb83bE4GFOHnydbdH5OU8ZoyQiotLE4oZMxp7zCRi/8RSeXD2TmJaNd7acxQvBHkh/pEK9ak4GjyciItPA4oZMglojMHdHjF5hAwACgALA+dtpOPx2e1hZcB09EZEp4095MgnHYlN1pqKeJAAkpGXj5M37ZRcUERHJgiM3VOFtPXUL30TdMKpvUkbhBRAREZkGjtxQhZGn1uBU3H38cCxOp/3IlWScuZVm1DncHZSlERoREZUjHLmhcutRrhoZOSptQZL2SIWXVkYBALo+54mqdlYAgD4NvVHDzQ7fRN1AysNcg+tuFAA8nfIvCyciItPGkRsql7775ybqz92LRbsuattc7K3RLMAZnYM9kJGdp21vV8cdb3aohfkvhgDIL2QeV/B4dq9g3qyPiKgSYHFDslu+/yp6fn4E/975b2rJ19kWKrVAbEqmTt8fXw/D6mFN4Otiq3eeriFeiBjSGJ5OulNPnk5KRAxpjK4hXqXzBoiIqFzhtBSVmfRsFQ5eTMLd9Gy81qamtv387XScv52Of66n4jnv/HvQNPV3xh9vt0d1ZxtJr9E1xAudgj0N3qGYiIgqBxY3JUStEfgnNhUnkxVwiU1FWKB7hfiFWthWBU977mmEELiZkgVzMwWqO+ePsiRn5GDyptOwsjDDsDB/mP+v7/AwX/RrUh1hj+3GrbQ0Nzg6YwxzMwXCanJnbyKiyorFTQnQveW/OTZcOQEvJyVm9wou11MhhW1VMLtXMAAU+pyh96TRCJg9Vvgs2n0RX/1xHaNaBuCD/50vwNUObWq7oba7PbJVathZ5vdvXcsVlpaWpfIeiYio8mFx84yKuuX/+I2nyu1aj6LiHrfxlMFjDL0nIQQmfHcKUddSsHNSK1Srmj/a8pyPE6zMzZCV+9/CX4VCgQ2jmmkfq1Sqkn1TRERE4ILiZ/K0W/4D+aMfao2hHvIxJm5DxP++pv10VvueFAoFEtKykfZIhWOxqdq+nYM9cHZOZyzqV78kQyciInoqjtw8A2Nv+X8sNhW/X7iLa/ce4s0OtRDqVxUAEHMnHUv2XoRPFRt81Lee9rgley4iJiEdr7epqV07cjXpIebvjIGrvTU+eaWBtu9nv19BdPx9jGjhj3Z13AEA8alZmPXreTgqLbFiUCNt34hD1/BPbApCfasWGffTPMzJwz/XU9Ai0BUAMKNbXSgtzfGct6O2j9LSvLDDiYiIShVHbp6BsbfyT8rIxqm4+zh06R5SHuZo2x88ysWhS/dw/EaqTv8ztx7g0KV7OufPyFbh0KV7OHo9RafvudtpOHTpHhIfK1ayctU4dOkeoq4l6/SNSUjHoUv3EJuse3l1cTz+es1ruKBh9SqwNOfHiYiI5MeRm2dg7K383R2UmNShFlIyc/Gcj5O2PdDNHp+80gCOSt3/htfb1ETfRtXQqHpVbZuvsy0+eaUB7Kx0R0RGtfRH1xBPNPatom3zdFTik1cawPqJ3a+HPO+LtrXdACGwNfq2sW/TIK8q0i7RJiIiKissbp5BswBneDkpkZiW/dRb/hu6hNrdUYmXQ6vptbep7abX5mJvbbBvwdTQ45xsLQ32fb6GC55H/pqbpZGXC427KNzGgIiIyjvZ5xFWrlyJgIAAKJVKhIaG4siRI0X2P3z4MEJDQ6FUKlGjRg2sWrWqjCLVZ26m0F42XZFu+W9M3EU9Vx7fExERUQFZi5vNmzdjypQpeO+99xAdHY3WrVujW7duiIuLM9g/NjYW3bt3R+vWrREdHY13330XkyZNws8//1zGkf+not7yv6i4Vw1pjFUV8D0REREBMk9LLVu2DKNHj8aYMWMAAMuXL8fevXsRERGBhQsX6vVftWoVfH19sXz5cgBAUFAQTpw4gU8++QT9+vUry9B1FNzy/++rSdh35B90bv18hbhD8dO2KuA2BkREVBHJVtzk5ubi5MmTmDFjhk57586dERUVZfCYv//+G507d9Zp69KlC9asWQOVSiXrXW7NzRR4PsAZKRcEnq9ARUBRWxVwGwMiIqqIZCtukpOToVar4eHhodPu4eGBxMREg8ckJiYa7J+Xl4fk5GR4eelPl+Tk5CAn57/Lr9PS8neeTk1NLfE75KpUKmRlZSElJYXbCRiB+ZKOOZOG+ZKOOZOG+ZLmWfKVkZEBIP/O+E8j+9VSCoXuCIcQQq/taf0NtRdYuHAh5s6dq9ceEBAgNVQiIiKSWUZGBpycnIrsI1tx4+rqCnNzc71RmqSkJL3RmQKenp4G+1tYWMDFxfD0ycyZMxEeHq59rNFokJqaChcXlyKLqOJIT09H9erVER8fD0dHx6cfUMkxX9IxZ9IwX9IxZ9IwX9I8S76EEMjIyIC3t/dT+8pW3FhZWSE0NBSRkZHo27evtj0yMhJ9+vQxeExYWBh27Nih07Zv3z40adKk0OEta2trWFtb67RVqVLl2YJ/CkdHR37IJWC+pGPOpGG+pGPOpGG+pCluvp42YlNA1kvBw8PD8X//939Yu3YtLly4gLfeegtxcXEYN24cgPxRl2HDhmn7jxs3Djdv3kR4eDguXLiAtWvXYs2aNZg2bZpcb4GIiIjKGVnX3AwYMAApKSmYN28eEhISEBISgl27dsHPzw8AkJCQoHPPm4CAAOzatQtvvfUWvvzyS3h7e2PFihWyXgZORERE5YvsC4onTJiACRMmGHxu/fr1em1t27bFqVOnSjmq4rG2tsbs2bP1psHIMOZLOuZMGuZLOuZMGuZLmrLKl0IYc00VERERUQUh+95SRERERCWJxQ0RERGZFBY3REREZFJY3BAREZFJYXFTQlauXImAgAAolUqEhobiyJEjcodUbvzxxx/o1asXvL29oVAo8Msvv+g8L4TAnDlz4O3tDRsbG7Rr1w7//vuvPMGWAwsXLkTTpk3h4OAAd3d3vPjii7h06ZJOH+bsPxEREahfv772pmBhYWHYvXu39nnmqmgLFy6EQqHAlClTtG3Mma45c+ZAoVDofHl6emqfZ74Mu337NoYMGQIXFxfY2tqiYcOGOHnypPb50swbi5sSsHnzZkyZMgXvvfceoqOj0bp1a3Tr1k3nHj2VWWZmJho0aIAvvvjC4PNLlizBsmXL8MUXX+D48ePw9PREp06dtJukVTaHDx/GG2+8gaNHjyIyMhJ5eXno3LkzMjMztX2Ys/9Uq1YNixYtwokTJ3DixAl06NABffr00f6QZK4Kd/z4caxevRr169fXaWfO9D333HNISEjQfp07d077HPOl7/79+2jZsiUsLS2xe/duxMTEYOnSpTo7BJRq3gQ9s2bNmolx48bptNWtW1fMmDFDpojKLwBi27Zt2scajUZ4enqKRYsWaduys7OFk5OTWLVqlQwRlj9JSUkCgDh8+LAQgjkzRtWqVcX//d//MVdFyMjIELVq1RKRkZGibdu2YvLkyUIIfr4MmT17tmjQoIHB55gvw9555x3RqlWrQp8v7bxx5OYZ5ebm4uTJk+jcubNOe+fOnREVFSVTVBVHbGwsEhMTdfJnbW2Ntm3bMn//k5aWBgBwdnYGwJwVRa1WY9OmTcjMzERYWBhzVYQ33ngDPXr0wAsvvKDTzpwZduXKFXh7eyMgIAADBw7E9evXATBfhdm+fTuaNGmCV155Be7u7mjUqBG+/vpr7fOlnTcWN88oOTkZarVabydzDw8PvR3MSV9Bjpg/w4QQCA8PR6tWrRASEgKAOTPk3LlzsLe3h7W1NcaNG4dt27YhODiYuSrEpk2bcOrUKSxcuFDvOeZM3/PPP48NGzZg7969+Prrr5GYmIgWLVogJSWF+SrE9evXERERgVq1amHv3r0YN24cJk2ahA0bNgAo/c+Z7NsvmAqFQqHzWAih10aFY/4MmzhxIs6ePYs///xT7znm7D916tTB6dOn8eDBA/z8888YPnw4Dh8+rH2eufpPfHw8Jk+ejH379kGpVBbajzn7T7du3bT/rlevHsLCwlCzZk188803aN68OQDm60kajQZNmjTBggULAACNGjXCv//+i4iICJ0NsUsrbxy5eUaurq4wNzfXqzSTkpL0KlLSV3DFAfOn780338T27dtx8OBBVKtWTdvOnOmzsrJCYGAgmjRpgoULF6JBgwb47LPPmCsDTp48iaSkJISGhsLCwgIWFhY4fPgwVqxYAQsLC21emLPC2dnZoV69erhy5Qo/Y4Xw8vJCcHCwTltQUJD2QpvSzhuLm2dkZWWF0NBQREZG6rRHRkaiRYsWMkVVcQQEBMDT01Mnf7m5uTh8+HClzZ8QAhMnTsTWrVtx4MABBAQE6DzPnD2dEAI5OTnMlQEdO3bEuXPncPr0ae1XkyZN8Oqrr+L06dOoUaMGc/YUOTk5uHDhAry8vPgZK0TLli31bmFx+fJl+Pn5ASiDn2PPvCSZxKZNm4SlpaVYs2aNiImJEVOmTBF2dnbixo0bcodWLmRkZIjo6GgRHR0tAIhly5aJ6OhocfPmTSGEEIsWLRJOTk5i69at4ty5c2LQoEHCy8tLpKenyxy5PMaPHy+cnJzEoUOHREJCgvYrKytL24c5+8/MmTPFH3/8IWJjY8XZs2fFu+++K8zMzMS+ffuEEMyVMR6/WkoI5uxJU6dOFYcOHRLXr18XR48eFT179hQODg7an/HMl75jx44JCwsL8dFHH4krV66I7777Ttja2oqNGzdq+5Rm3ljclJAvv/xS+Pn5CSsrK9G4cWPtZbskxMGDBwUAva/hw4cLIfIvCZw9e7bw9PQU1tbWok2bNuLcuXPyBi0jQ7kCINatW6ftw5z9Z9SoUdrvPTc3N9GxY0dtYSMEc2WMJ4sb5kzXgAEDhJeXl7C0tBTe3t7ipZdeEv/++6/2eebLsB07doiQkBBhbW0t6tatK1avXq3zfGnmTSGEEM8+/kNERERUPnDNDREREZkUFjdERERkUljcEBERkUlhcUNEREQmhcUNERERmRQWN0RERGRSWNwQERGRSWFxQ0T0hDlz5qBhw4Zyh0FExcTihojK3L1792BpaYmsrCzk5eXBzs5Ou6EeAPj7+2P58uV6x7HoICJjsLghojL3999/o2HDhrC1tcXJkyfh7OwMX19fucMiIhPB4oaIylxUVBRatmwJAPjzzz+1/y6OdevWISgoCEqlEnXr1sXKlSt1nn/nnXdQu3Zt2NraokaNGpg1axZUKpVOn0WLFsHDwwMODg4YPXo0srOzdZ4/dOgQmjVrBjs7O1SpUgUtW7bEzZs3ix0zEZUuC7kDIKLKIS4uDvXr1wcAZGVlwdzcHOvXr8ejR4+gUChQpUoVDB48WK84KcrXX3+N2bNn44svvkCjRo0QHR2NsWPHws7ODsOHDwcAODg4YP369fD29sa5c+cwduxYODg4YPr06QCAH3/8EbNnz8aXX36J1q1b49tvv8WKFStQo0YNAEBeXh5efPFFjB07Fj/88ANyc3Nx7NgxKBSKEs4QEZUUbpxJRGUiLy8Pt27dQnp6Opo0aYLjx4/D3t4eDRs2xM6dO+Hr6wt7e3u4urrC398fCQkJsLS01DlHbm4ugoODcfr0aQCAr68vFi9ejEGDBmn7zJ8/H7t27UJUVJTBOD7++GNs3rwZJ06cAAC0aNECDRo0QEREhLZP8+bNkZ2djdOnTyM1NRUuLi44dOgQ2rZtW8JZIaLSwGkpIioTFhYW8Pf3x8WLF9G0aVM0aNAAiYmJ8PDwQJs2beDv7w9XV1dt/7fffhunT5/W+Ro3bpz2+Xv37iE+Ph6jR4+Gvb299mv+/Pm4du2att+WLVvQqlUreHp6wt7eHrNmzdJZvHzhwgWEhYXpxPr4Y2dnZ4wYMQJdunRBr1698NlnnyEhIaE0UkREJYTTUkRUJp577jncvHkTKpUKGo0G9vb2yMvLQ15eHuzt7eHn54d///1X29/V1RWBgYE653B2dtb+W6PRAMifmnr++ed1+pmbmwMAjh49ioEDB2Lu3Lno0qULnJycsGnTJixdulRS7OvWrcOkSZOwZ88ebN68Ge+//z4iIyPRvHlzSechorLB4oaIysSuXbugUqnQsWNHLFmyBKGhoRg4cCBGjBiBrl276k1BPY2Hhwd8fHxw/fp1vPrqqwb7/PXXX/Dz88N7772nbXtyIXBQUBCOHj2KYcOGaduOHj2qd65GjRqhUaNGmDlzJsLCwvD999+zuCEqp1jcEFGZ8PPzQ2JiIu7evYs+ffrAzMwMMTExeOmll+Dt7V2sc86ZMweTJk2Co6MjunXrhpycHJw4cQL3799HeHg4AgMDERcXh02bNqFp06bYuXMntm3bpnOOyZMnY/jw4WjSpAlatWqF7777Dv/++692QXFsbCxWr16N3r17w9vbG5cuXcLly5d1iiEiKl9Y3BBRmTl06BCaNm0KpVKJI0eOwMfHp9iFDQCMGTMGtra2+PjjjzF9+nTY2dmhXr16mDJlCgCgT58+eOuttzBx4kTk5OSgR48emDVrFubMmaM9x4ABA3Dt2jW88847yM7ORr9+/TB+/Hjs3bsXAGBra4uLFy/im2++QUpKCry8vDBx4kS8/vrrz5IKIipFvFqKiIiITAqvliIiIiKTwuKGiIiITAqLGyIiIjIpLG6IiIjIpLC4ISIiIpPC4oaIiIhMCosbIiIiMiksboiIiMiksLghIiIik8LihoiIiEwKixsiIiIyKSxuiIiIyKT8P03LtHxEalbUAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot valid_acc vs num_heads\n",
    "\n",
    "plt.plot(num_heads, valid_acc, \"o:\")\n",
    "plt.xlabel(\"#Heads\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.title(\"Correct Object Value Fetcher Heads\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Path Patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">14</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>rounded = torch.round(mask.data)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>masked_heads = compute_heads_from_mask(rounded)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>masked_heads = [(l, h) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> l, h <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> masked_heads]                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>14 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>pp_heads = analysis_utils.compute_topk_components(                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch.tensor(logit_values), k=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(masked_heads), largest=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>)                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>pp_heads = [(l, h) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> l, h <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> pp_heads]                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/local_nikhil/Projects/Anima-2.0/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">analysis_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">161</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_topk_components</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">158 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_topk_components</span>(patching_scores: torch.Tensor, k: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>, largest=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>):          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">160 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Computes the topk most influential components (i.e. heads) for patching.\"\"\"</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>161 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>top_indices = torch.topk(patching_scores.flatten(), k, largest=largest).indices        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Convert the top_indices to 2D indices</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>row_indices = top_indices // patching_scores.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>selected index k out of range\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m14\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m│   \u001b[0mrounded = torch.round(mask.data)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m12 \u001b[0m\u001b[2m│   \u001b[0mmasked_heads = compute_heads_from_mask(rounded)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m│   \u001b[0mmasked_heads = [(l, h) \u001b[94mfor\u001b[0m l, h \u001b[95min\u001b[0m masked_heads]                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m14 \u001b[2m│   \u001b[0mpp_heads = analysis_utils.compute_topk_components(                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m\u001b[2m│   │   \u001b[0mtorch.tensor(logit_values), k=\u001b[96mlen\u001b[0m(masked_heads), largest=\u001b[94mFalse\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0m\u001b[2m│   \u001b[0m)                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m17 \u001b[0m\u001b[2m│   \u001b[0mpp_heads = [(l, h) \u001b[94mfor\u001b[0m l, h \u001b[95min\u001b[0m pp_heads]                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/local_nikhil/Projects/Anima-2.0/\u001b[0m\u001b[1;33manalysis_utils.py\u001b[0m:\u001b[94m161\u001b[0m in \u001b[92mcompute_topk_components\u001b[0m           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_topk_components\u001b[0m(patching_scores: torch.Tensor, k: \u001b[96mint\u001b[0m, largest=\u001b[94mTrue\u001b[0m):          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2;90m│   \u001b[0m\u001b[33m\"\"\"Computes the topk most influential components (i.e. heads) for patching.\"\"\"\u001b[0m         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m161 \u001b[2m│   \u001b[0mtop_indices = torch.topk(patching_scores.flatten(), k, largest=largest).indices        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Convert the top_indices to 2D indices\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   \u001b[0mrow_indices = top_indices // patching_scores.shape[\u001b[94m1\u001b[0m]                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mselected index k out of range\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask_path = './masks/reverse/last_pos/correct_object_value_fetcher/'\n",
    "masks = sorted([float(mask) for mask in os.listdir(mask_path) if '.png' not in mask])\n",
    "\n",
    "pp_path = \"./new_pp_exps/reverse/direct_logits_heads.pt\"\n",
    "logit_values = torch.load(pp_path)\n",
    "\n",
    "precision = []\n",
    "num_heads = []\n",
    "for lamb in masks:\n",
    "    mask = torch.load(f\"{path}/{lamb}\")\n",
    "    rounded = torch.round(mask.data)\n",
    "    masked_heads = compute_heads_from_mask(rounded)\n",
    "    masked_heads = [(l, h) for l, h in masked_heads]\n",
    "    pp_heads = analysis_utils.compute_topk_components(\n",
    "        logit_values, k=len(masked_heads), largest=False\n",
    "    )\n",
    "    pp_heads = [(l, h) for l, h in pp_heads]\n",
    "    # Compute precision and recall between masked_heads and pp_heads without scikit-learn\n",
    "    precision.append(round(len(set(masked_heads).intersection(set(pp_heads))) / len(pp_heads), 2))\n",
    "    num_heads.append(len(masked_heads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot precision vs num_heads\n",
    "plt.plot(num_heads, precision, \"o:\")\n",
    "plt.xlabel(\"#Heads\")\n",
    "plt.ylabel(\"Precision & Recall\")\n",
    "plt.title(\"Correct Object Position Fetcher Heads\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anima",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
