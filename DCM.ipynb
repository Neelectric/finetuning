{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_nikhil/.conda/envs/anima/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f147f5ecd10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from baukit import TraceDict\n",
    "from einops import rearrange, einsum\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from datasets import Dataset\n",
    "from model_aligner_script import load_data\n",
    "from counterfactual_datasets.entity_tracking import object_alignment_example_sampler\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file tokenizer.model\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "path = \"./llama_7b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "# model = AutoModelForCausalLM.from_pretrained(path).to(DEVICE)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# model.eval()\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HEADS = model.config.num_attention_heads\n",
    "HEAD_SIZE = model.config.hidden_size // NUM_HEADS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desiderata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = \"./box_datasets/no_instructions/original/3/train.jsonl\"\n",
    "object_file_path = \"./box_datasets/objects_with_bnc_frequency.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  400\n",
      "Eval size:  50\n",
      "Test size:  50\n"
     ]
    }
   ],
   "source": [
    "objValueFetcher_train, objValueFetcher_eval, objValueFetcher_test = load_data(\n",
    "    tokenizer=tokenizer,\n",
    "    data_size=500,\n",
    "    aligner_func=object_alignment_example_sampler,\n",
    "    data_file=data_file_path,\n",
    "    num_ents_or_ops=3,\n",
    "    batch_size=30,\n",
    "    architecture=\"\",\n",
    "    object_file=object_file_path,\n",
    "    alt_examples=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "desiderata_train = [objValueFetcher_train]\n",
    "desiderata_eval = [objValueFetcher_eval]\n",
    "desiderata_valid = [objValueFetcher_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Box 0 contains boot, Box 1 contains lunchbox, Box 2 contains bell. Box 0 contains</s></s></s></s></s></s></s>\n",
      "  Box 0 contains stone, Box 1 contains lunchbox, Box 2 contains bell. Box 0 contains</s></s></s></s></s></s></s>\n",
      " stone\n"
     ]
    }
   ],
   "source": [
    "data = next(enumerate(desiderata_train[0]))[1]\n",
    "print(tokenizer.decode(data[\"base_input_ids\"][0]))\n",
    "print(tokenizer.decode(data[\"source_input_ids\"][0]))\n",
    "print(tokenizer.decode(data[\"labels\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Binary Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = [f\"model.layers.{i}.self_attn.o_proj\" for i in range(model.config.num_hidden_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_activations_valid = {}\n",
    "\n",
    "for di, desid_train in enumerate(desiderata_train):\n",
    "    source_activations_valid[di] = {}\n",
    "\n",
    "    for bi, inputs in enumerate(desid_train):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(DEVICE)\n",
    "\n",
    "        source_activations_valid[di][bi] = {}\n",
    "        with torch.no_grad():\n",
    "            with TraceDict(model, modules, retain_input=True) as trace:\n",
    "                _ = model(inputs[\"source_input_ids\"])\n",
    "\n",
    "                for module in modules:\n",
    "                    if \"self_attn\" in module:\n",
    "                        source_activations_valid[di][bi][module] = trace[module].input.detach().cpu()\n",
    "                    else:\n",
    "                        source_activations_valid[di][bi][module] = trace[module].output.detach().cpu()\n",
    "\n",
    "        del trace\n",
    "        torch.cuda.empty_cache()\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules_w_heads = []\n",
    "for module in modules:\n",
    "    if \"self_attn\" in module:\n",
    "        for head in range(model.config.num_attention_heads):\n",
    "            modules_w_heads.append(f\"{module}.{head}\")\n",
    "    else:\n",
    "        modules_w_heads.append(module)\n",
    "\n",
    "mask_dict = {module: i for i, module in enumerate(modules_w_heads)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_output(inputs, output, layer, mask, from_activations, to_last_token_pos, from_last_token_pos):\n",
    "    if \"self_attn\" in layer:\n",
    "        inp = inputs[0]\n",
    "        from_activations[layer] = from_activations[layer].to(DEVICE)\n",
    "\n",
    "        # Computing the output of each head in this layer after the intervention\n",
    "        heads_out_post_intervention = []\n",
    "        for head_idx in range(NUM_HEADS):\n",
    "            head_start = head_idx * HEAD_SIZE\n",
    "            head_end = (head_idx + 1) * HEAD_SIZE\n",
    "            abl_amt = mask[mask_dict[f\"{layer}.{head_idx}\"]]\n",
    "\n",
    "            head_out = []\n",
    "            for bi in range(inp.shape[0]):\n",
    "                intervened_head_output = abl_amt * inp[bi, to_last_token_pos[bi], head_start:head_end] + (1 - abl_amt) * from_activations[layer][bi, from_last_token_pos[bi], head_start:head_end]\n",
    "                inp[bi, to_last_token_pos[bi], head_start:head_end] = intervened_head_output\n",
    "\n",
    "        from_activations[layer] = from_activations[layer].to(\"cpu\")\n",
    "\n",
    "        weights = model.state_dict()[f\"{layer}.weight\"]\n",
    "        mod_output = torch.einsum(\"bsh,oh->bso\", inp, weights)\n",
    "\n",
    "        del weights\n",
    "        torch.cuda.empty_cache()\n",
    "        return mod_output\n",
    "\n",
    "    else:\n",
    "        assert False, \"shouldn't be here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask.data.clamp_(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Learned Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounded = [torch.round(mask) for mask in masks.values()]\n",
    "# (rounded[0] == 0).nonzero().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = [f\"model.layers.{i}.self_attn.o_proj\" for i in range(model.config.num_hidden_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_activations_valid = {}\n",
    "\n",
    "for di, desid_train in enumerate(desiderata_train):\n",
    "    source_activations_valid[di] = {}\n",
    "\n",
    "    for bi, inputs in enumerate(desid_train):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(DEVICE)\n",
    "\n",
    "        source_activations_valid[di][bi] = {}\n",
    "        with torch.no_grad():\n",
    "            with TraceDict(model, modules, retain_input=True) as trace:\n",
    "                _ = model(inputs[\"base_input_ids\"])\n",
    "\n",
    "                for module in modules:\n",
    "                    if \"self_attn\" in module:\n",
    "                        source_activations_valid[di][bi][module] = trace[module].input.detach().cpu()\n",
    "                    else:\n",
    "                        source_activations_valid[di][bi][module] = trace[module].output.detach().cpu()\n",
    "\n",
    "        del trace\n",
    "        torch.cuda.empty_cache()\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for round_mask in [torch.ones(model.config.num_hidden_layers * model.config.num_attention_heads)]:\n",
    "        count, total = 0, 0\n",
    "        for di, desid_valid in enumerate(desiderata_train):\n",
    "            accuracy = []\n",
    "            for bi, inputs in enumerate(desid_train):\n",
    "                with TraceDict(\n",
    "                    model,\n",
    "                    modules,\n",
    "                    edit_output=partial(\n",
    "                        dummy_edit,\n",
    "                        mask=round_mask,\n",
    "                        from_activations=source_activations_valid[di][bi],\n",
    "                        to_last_token_pos=inputs[\"source_input_last_pos\"],\n",
    "                        from_last_token_pos=inputs[\"base_input_last_pos\"],\n",
    "                    ),\n",
    "                ) as _:\n",
    "                    outputs = model(inputs['source_input_ids'].to(DEVICE))\n",
    "\n",
    "                for i in range(inputs['source_input_ids'].size(0)):\n",
    "                    logits = outputs.logits[i, inputs['source_input_last_pos'][i]]\n",
    "                    pred = torch.argmax(logits, dim=-1)\n",
    "                    label = inputs['labels'][i]\n",
    "\n",
    "                    if pred == label:\n",
    "                        count += 1\n",
    "\n",
    "                total += inputs['source_input_ids'].size(0)\n",
    "            \n",
    "        print(f'Accuracy: {count / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nothing\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Box 0 contains jacket, Box 1 contains nothing, Box 2 contains lantern. Box 2 contains\"\n",
    "tokens = tokenizer(prompt, return_tensors='pt').input_ids.to(DEVICE)\n",
    "output = model(tokens)\n",
    "pred = torch.argmax(output.logits[0, -1], dim=-1)\n",
    "print(tokenizer.decode(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Box 0 contains cash, Box 1 contains contrabass, Box 2 contains nametag. Box 0 contains</s></s></s>'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs['source_input_ids'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anima",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
