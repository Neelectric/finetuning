{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "014efce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from functools import partial\n",
    "from baukit import TraceDict\n",
    "from einops import rearrange, einsum\n",
    "from tqdm import tqdm\n",
    "\n",
    "from cmap_utils import get_model_and_tokenizer, load_data, eval_model_performance, cmap_in, cmap_out\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(10)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc9e7e3",
   "metadata": {},
   "source": [
    "### Loading Models and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e0c6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d5153ff2a94245ab173e89f8960097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ffd75d260434c9489094eaad448ca60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llama_model, tokenizer = get_model_and_tokenizer(model_name=\"llama\", device=device)\n",
    "goat_model, _ = get_model_and_tokenizer(model_name=\"goat\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2bbc13",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "767b0032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 500\n"
     ]
    }
   ],
   "source": [
    "data_file = \"../data/dataset.jsonl\"\n",
    "dataloader = load_data(tokenizer=tokenizer, data_file=data_file, num_samples=500, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7764d3e",
   "metadata": {},
   "source": [
    "### Models Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc32e9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/63 [00:00<00:31,  1.98it/s]\n",
      "  3%|▎         | 2/63 [00:00<00:26,  2.31it/s]\n",
      "  5%|▍         | 3/63 [00:01<00:24,  2.45it/s]\n",
      "  6%|▋         | 4/63 [00:01<00:23,  2.51it/s]\n",
      "  8%|▊         | 5/63 [00:02<00:22,  2.55it/s]\n",
      " 10%|▉         | 6/63 [00:02<00:22,  2.58it/s]\n",
      " 11%|█         | 7/63 [00:02<00:21,  2.59it/s]\n",
      " 13%|█▎        | 8/63 [00:03<00:21,  2.60it/s]\n",
      " 14%|█▍        | 9/63 [00:03<00:20,  2.61it/s]\n",
      " 16%|█▌        | 10/63 [00:03<00:20,  2.61it/s]\n",
      " 17%|█▋        | 11/63 [00:04<00:19,  2.62it/s]\n",
      " 19%|█▉        | 12/63 [00:04<00:19,  2.62it/s]\n",
      " 21%|██        | 13/63 [00:05<00:19,  2.62it/s]\n",
      " 22%|██▏       | 14/63 [00:05<00:18,  2.62it/s]\n",
      " 24%|██▍       | 15/63 [00:05<00:18,  2.62it/s]\n",
      " 25%|██▌       | 16/63 [00:06<00:17,  2.62it/s]\n",
      " 27%|██▋       | 17/63 [00:06<00:17,  2.62it/s]\n",
      " 29%|██▊       | 18/63 [00:06<00:17,  2.62it/s]\n",
      " 30%|███       | 19/63 [00:07<00:16,  2.62it/s]\n",
      " 32%|███▏      | 20/63 [00:07<00:16,  2.62it/s]\n",
      " 33%|███▎      | 21/63 [00:08<00:16,  2.62it/s]\n",
      " 35%|███▍      | 22/63 [00:08<00:15,  2.62it/s]\n",
      " 37%|███▋      | 23/63 [00:08<00:15,  2.62it/s]\n",
      " 38%|███▊      | 24/63 [00:09<00:14,  2.62it/s]\n",
      " 40%|███▉      | 25/63 [00:09<00:14,  2.62it/s]\n",
      " 41%|████▏     | 26/63 [00:10<00:14,  2.62it/s]\n",
      " 43%|████▎     | 27/63 [00:10<00:13,  2.62it/s]\n",
      " 44%|████▍     | 28/63 [00:10<00:13,  2.62it/s]\n",
      " 46%|████▌     | 29/63 [00:11<00:12,  2.63it/s]\n",
      " 48%|████▊     | 30/63 [00:11<00:12,  2.63it/s]\n",
      " 49%|████▉     | 31/63 [00:11<00:12,  2.63it/s]\n",
      " 51%|█████     | 32/63 [00:12<00:11,  2.63it/s]\n",
      " 52%|█████▏    | 33/63 [00:12<00:11,  2.63it/s]\n",
      " 54%|█████▍    | 34/63 [00:13<00:11,  2.63it/s]\n",
      " 56%|█████▌    | 35/63 [00:13<00:10,  2.63it/s]\n",
      " 57%|█████▋    | 36/63 [00:13<00:10,  2.63it/s]\n",
      " 59%|█████▊    | 37/63 [00:14<00:09,  2.62it/s]\n",
      " 60%|██████    | 38/63 [00:14<00:09,  2.62it/s]\n",
      " 62%|██████▏   | 39/63 [00:14<00:09,  2.62it/s]\n",
      " 63%|██████▎   | 40/63 [00:15<00:08,  2.62it/s]\n",
      " 65%|██████▌   | 41/63 [00:15<00:08,  2.62it/s]\n",
      " 67%|██████▋   | 42/63 [00:16<00:08,  2.62it/s]\n",
      " 68%|██████▊   | 43/63 [00:16<00:07,  2.63it/s]\n",
      " 70%|██████▉   | 44/63 [00:16<00:07,  2.63it/s]\n",
      " 71%|███████▏  | 45/63 [00:17<00:06,  2.63it/s]\n",
      " 73%|███████▎  | 46/63 [00:17<00:06,  2.63it/s]\n",
      " 75%|███████▍  | 47/63 [00:18<00:06,  2.63it/s]\n",
      " 76%|███████▌  | 48/63 [00:18<00:05,  2.63it/s]\n",
      " 78%|███████▊  | 49/63 [00:18<00:05,  2.63it/s]\n",
      " 79%|███████▉  | 50/63 [00:19<00:04,  2.63it/s]\n",
      " 81%|████████  | 51/63 [00:19<00:04,  2.63it/s]\n",
      " 83%|████████▎ | 52/63 [00:19<00:04,  2.63it/s]\n",
      " 84%|████████▍ | 53/63 [00:20<00:03,  2.63it/s]\n",
      " 86%|████████▌ | 54/63 [00:20<00:03,  2.63it/s]\n",
      " 87%|████████▋ | 55/63 [00:21<00:03,  2.63it/s]\n",
      " 89%|████████▉ | 56/63 [00:21<00:02,  2.63it/s]\n",
      " 90%|█████████ | 57/63 [00:21<00:02,  2.63it/s]\n",
      " 92%|█████████▏| 58/63 [00:22<00:01,  2.63it/s]\n",
      " 94%|█████████▎| 59/63 [00:22<00:01,  2.63it/s]\n",
      " 95%|█████████▌| 60/63 [00:22<00:01,  2.63it/s]\n",
      " 97%|█████████▋| 61/63 [00:23<00:00,  2.63it/s]\n",
      " 98%|█████████▊| 62/63 [00:23<00:00,  2.63it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.63it/s]\n",
      "63it [00:23,  2.63it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/63 [00:00<00:24,  2.52it/s]\n",
      "  3%|▎         | 2/63 [00:00<00:23,  2.54it/s]\n",
      "  5%|▍         | 3/63 [00:01<00:23,  2.55it/s]\n",
      "  6%|▋         | 4/63 [00:01<00:23,  2.55it/s]\n",
      "  8%|▊         | 5/63 [00:01<00:22,  2.55it/s]\n",
      " 10%|▉         | 6/63 [00:02<00:22,  2.55it/s]\n",
      " 11%|█         | 7/63 [00:02<00:21,  2.56it/s]\n",
      " 13%|█▎        | 8/63 [00:03<00:21,  2.56it/s]\n",
      " 14%|█▍        | 9/63 [00:03<00:21,  2.56it/s]\n",
      " 16%|█▌        | 10/63 [00:03<00:20,  2.56it/s]\n",
      " 17%|█▋        | 11/63 [00:04<00:20,  2.56it/s]\n",
      " 19%|█▉        | 12/63 [00:04<00:19,  2.56it/s]\n",
      " 21%|██        | 13/63 [00:05<00:19,  2.56it/s]\n",
      " 22%|██▏       | 14/63 [00:05<00:19,  2.56it/s]\n",
      " 24%|██▍       | 15/63 [00:05<00:18,  2.56it/s]\n",
      " 25%|██▌       | 16/63 [00:06<00:18,  2.56it/s]\n",
      " 27%|██▋       | 17/63 [00:06<00:17,  2.56it/s]\n",
      " 29%|██▊       | 18/63 [00:07<00:17,  2.56it/s]\n",
      " 30%|███       | 19/63 [00:07<00:17,  2.56it/s]\n",
      " 32%|███▏      | 20/63 [00:07<00:16,  2.56it/s]\n",
      " 33%|███▎      | 21/63 [00:08<00:16,  2.56it/s]\n",
      " 35%|███▍      | 22/63 [00:08<00:16,  2.56it/s]\n",
      " 37%|███▋      | 23/63 [00:09<00:15,  2.56it/s]\n",
      " 38%|███▊      | 24/63 [00:09<00:15,  2.56it/s]\n",
      " 40%|███▉      | 25/63 [00:09<00:14,  2.56it/s]\n",
      " 41%|████▏     | 26/63 [00:10<00:14,  2.56it/s]\n",
      " 43%|████▎     | 27/63 [00:10<00:14,  2.56it/s]\n",
      " 44%|████▍     | 28/63 [00:10<00:13,  2.56it/s]\n",
      " 46%|████▌     | 29/63 [00:11<00:13,  2.56it/s]\n",
      " 48%|████▊     | 30/63 [00:11<00:12,  2.56it/s]\n",
      " 49%|████▉     | 31/63 [00:12<00:12,  2.56it/s]\n",
      " 51%|█████     | 32/63 [00:12<00:12,  2.56it/s]\n",
      " 52%|█████▏    | 33/63 [00:12<00:11,  2.56it/s]\n",
      " 54%|█████▍    | 34/63 [00:13<00:11,  2.56it/s]\n",
      " 56%|█████▌    | 35/63 [00:13<00:10,  2.56it/s]\n",
      " 57%|█████▋    | 36/63 [00:14<00:10,  2.56it/s]\n",
      " 59%|█████▊    | 37/63 [00:14<00:10,  2.56it/s]\n",
      " 60%|██████    | 38/63 [00:14<00:09,  2.56it/s]\n",
      " 62%|██████▏   | 39/63 [00:15<00:09,  2.56it/s]\n",
      " 63%|██████▎   | 40/63 [00:15<00:08,  2.56it/s]\n",
      " 65%|██████▌   | 41/63 [00:16<00:08,  2.56it/s]\n",
      " 67%|██████▋   | 42/63 [00:16<00:08,  2.56it/s]\n",
      " 68%|██████▊   | 43/63 [00:16<00:07,  2.56it/s]\n",
      " 70%|██████▉   | 44/63 [00:17<00:07,  2.56it/s]\n",
      " 71%|███████▏  | 45/63 [00:17<00:07,  2.56it/s]\n",
      " 73%|███████▎  | 46/63 [00:17<00:06,  2.56it/s]\n",
      " 75%|███████▍  | 47/63 [00:18<00:06,  2.56it/s]\n",
      " 76%|███████▌  | 48/63 [00:18<00:05,  2.56it/s]\n",
      " 78%|███████▊  | 49/63 [00:19<00:05,  2.56it/s]\n",
      " 79%|███████▉  | 50/63 [00:19<00:05,  2.56it/s]\n",
      " 81%|████████  | 51/63 [00:19<00:04,  2.56it/s]\n",
      " 83%|████████▎ | 52/63 [00:20<00:04,  2.56it/s]\n",
      " 84%|████████▍ | 53/63 [00:20<00:03,  2.56it/s]\n",
      " 86%|████████▌ | 54/63 [00:21<00:03,  2.56it/s]\n",
      " 87%|████████▋ | 55/63 [00:21<00:03,  2.56it/s]\n",
      " 89%|████████▉ | 56/63 [00:21<00:02,  2.56it/s]\n",
      " 90%|█████████ | 57/63 [00:22<00:02,  2.56it/s]\n",
      " 92%|█████████▏| 58/63 [00:22<00:01,  2.56it/s]\n",
      " 94%|█████████▎| 59/63 [00:23<00:01,  2.56it/s]\n",
      " 95%|█████████▌| 60/63 [00:23<00:01,  2.56it/s]\n",
      " 97%|█████████▋| 61/63 [00:23<00:00,  2.56it/s]\n",
      " 98%|█████████▊| 62/63 [00:24<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [00:24<00:00,  2.57it/s]\n",
      "63it [00:24,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLAMA accuracy: 0.66\n",
      "Goat accuracy: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "llama_acc = eval_model_performance(llama_model, dataloader, device)\n",
    "goat_acc = eval_model_performance(goat_model, dataloader, device)\n",
    "\n",
    "print(f\"LLAMA accuracy: {llama_acc}\")\n",
    "print(f\"Goat accuracy: {goat_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70ce7ad",
   "metadata": {},
   "source": [
    "### Loading Model Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "247e0e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_modules = [[f\"model.layers.{layer}.self_attn.k_proj\", \n",
    "                  f\"model.layers.{layer}.self_attn.q_proj\",\n",
    "                  f\"model.layers.{layer}.self_attn.v_proj\",\n",
    "                 f\"model.layers.{layer}.self_attn.o_proj\"] \n",
    "                 for layer in range(llama_model.config.num_hidden_layers)]\n",
    "goat_modules = [[f\"base_model.model.model.layers.{layer}.self_attn.k_proj\", \n",
    "                 f\"base_model.model.model.layers.{layer}.self_attn.q_proj\",\n",
    "                 f\"base_model.model.model.layers.{layer}.self_attn.v_proj\",\n",
    "                f\"base_model.model.model.layers.{layer}.self_attn.o_proj\"] \n",
    "                for layer in range(goat_model.config.num_hidden_layers)]\n",
    "\n",
    "llama_modules = [item for sublist in llama_modules for item in sublist]\n",
    "goat_modules = [item for sublist in goat_modules for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e4dbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "goat_cache: 63it [00:46,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "goat_cache = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for bi, inputs in tqdm(enumerate(dataloader), desc=\"goat_cache\"):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(goat_model.device)\n",
    "\n",
    "        with TraceDict(goat_model, goat_modules, retain_input=True) as cache:\n",
    "            _ = goat_model(inputs[\"input_ids\"])\n",
    "        \n",
    "        for goat_layer, llama_layer in zip(goat_modules, llama_modules):\n",
    "            if \"o_proj\" in llama_layer and \"o_proj\" in goat_layer:\n",
    "                if bi in goat_cache:\n",
    "                    goat_cache[bi][llama_layer] = cache[goat_layer].input.cpu()\n",
    "                else:\n",
    "                    goat_cache[bi] = {}\n",
    "                    goat_cache[bi][llama_layer] = cache[goat_layer].input.cpu()\n",
    "            else:\n",
    "                if bi in goat_cache:\n",
    "                    goat_cache[bi][llama_layer] = cache[goat_layer].output.cpu()\n",
    "                else:\n",
    "                    goat_cache[bi] = {}\n",
    "                    goat_cache[bi][llama_layer] = cache[goat_layer].output.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9b229d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_cache: 63it [00:41,  1.51it/s]\n"
     ]
    }
   ],
   "source": [
    "llama_cache = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for bi, inputs in tqdm(enumerate(dataloader), desc=\"llama_cache\"):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(llama_model.device)\n",
    "\n",
    "        with TraceDict(llama_model, llama_modules, retain_input=True) as cache:\n",
    "            _ = llama_model(inputs[\"input_ids\"])\n",
    "        \n",
    "        for llama_layer in llama_modules:\n",
    "            if \"o_proj\" in llama_layer:\n",
    "                if bi in llama_cache:\n",
    "                    llama_cache[bi][llama_layer] = cache[llama_layer].input.cpu()\n",
    "                else:\n",
    "                    llama_cache[bi] = {}\n",
    "                    llama_cache[bi][llama_layer] = cache[llama_layer].input.cpu()\n",
    "            else:\n",
    "                if bi in llama_cache:\n",
    "                    llama_cache[bi][llama_layer] = cache[llama_layer].output.cpu()\n",
    "                else:\n",
    "                    llama_cache[bi] = {}\n",
    "                    llama_cache[bi][llama_layer] = cache[llama_layer].output.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16f118f",
   "metadata": {},
   "source": [
    "### Loading circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35e2f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../experiment_1/results/circuits/llama_circuit.json\", \"r\") as f:\n",
    "    circuit_heads = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "089e404e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Fetcher Heads: 40\n",
      "Heads affecting direct logit heads: 5\n",
      "Heads at query box token: 14\n",
      "Heads at prev query box token: 5\n"
     ]
    }
   ],
   "source": [
    "with open(\"../experiment_2/results/DCM/llama_circuit/value_fetcher/object_value/0.01.txt\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    value_fetcher = json.loads(data[0].split(\": \")[1])\n",
    "\n",
    "with open(\"../experiment_2/results/DCM/llama_circuit/pos_transmitter/positional/0.01.txt\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    pos_transmitter = json.loads(data[0].split(\": \")[1])\n",
    "\n",
    "with open(\"../experiment_2/results/DCM/llama_circuit/pos_detector/positional/0.01.txt\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    pos_detector = json.loads(data[0].split(\": \")[1])\n",
    "\n",
    "struct_reader = circuit_heads[\"struct_reader\"]\n",
    "\n",
    "print(f\"Value Fetcher Heads: {len(value_fetcher)}\")\n",
    "print(f\"Heads affecting direct logit heads: {len(pos_transmitter)}\")\n",
    "print(f\"Heads at query box token: {len(pos_detector)}\")\n",
    "print(f\"Heads at prev query box token: {len(struct_reader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec2b096",
   "metadata": {},
   "source": [
    "### CMAP (output patching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee702e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full circuit (Select group of heads for CMAP accordingly)\n",
    "pos_heads_dict = {}\n",
    "# pos_heads_dict[0] = value_fetcher\n",
    "# pos_heads_dict[0] = pos_transmitter\n",
    "# pos_heads_dict[2] = pos_detector\n",
    "pos_heads_dict[-1] = struct_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c95c5393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:32,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task accuracy: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct_count, total_count = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for bi, inputs in tqdm(enumerate(dataloader)):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(llama_model.device)\n",
    "\n",
    "        with TraceDict(llama_model,\n",
    "                       llama_modules,\n",
    "                       retain_input=True,\n",
    "                       edit_output=partial(\n",
    "                            cmap_out,\n",
    "                            model = llama_model,\n",
    "                            goat_cache = goat_cache,\n",
    "                            bi = bi,\n",
    "                            pos_heads_dict = pos_heads_dict,\n",
    "                            input_tokens = inputs)) as _:\n",
    "                outputs = llama_model(inputs[\"input_ids\"], output_attentions=True)\n",
    "\n",
    "        for bi in range(inputs[\"labels\"].size(0)):\n",
    "            label = inputs[\"labels\"][bi]\n",
    "            pred = torch.argmax(outputs.logits[bi][inputs[\"last_token_indices\"][bi]])\n",
    "\n",
    "            if label == pred:\n",
    "                correct_count += 1\n",
    "            total_count += 1\n",
    "\n",
    "        del outputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "current_acc = round(correct_count / total_count, 2)\n",
    "print(f\"Task accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741276db",
   "metadata": {},
   "source": [
    "Output CMAP Results:\n",
    "- Full Circuit: 0.78\n",
    "- Value Fetcher: 0.77\n",
    "- Position Transmitter: 0.68\n",
    "- Position Detector:0.62\n",
    "- Structure Reader: 0.67"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa17d88",
   "metadata": {},
   "source": [
    "### CMAP (input patching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2eb4a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select group of heads for CMAP accordingly\n",
    "pos_heads_dict = {}\n",
    "# pos_heads_dict[0] = value_fetcher\n",
    "pos_heads_dict[0] = pos_transmitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7627498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:38,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task accuracy: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct_count, total_count = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for bi, inputs in tqdm(enumerate(dataloader)):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(llama_model.device)\n",
    "\n",
    "        with TraceDict(llama_model,\n",
    "                       llama_modules,\n",
    "                       retain_input=True,\n",
    "                       edit_output=partial(\n",
    "                            cmap_in,\n",
    "                            model = llama_model,\n",
    "                            goat_cache = goat_cache,\n",
    "                            llama_cache = llama_cache,\n",
    "                            patching_component = [\"q_proj\", \"k_proj\", \"v_proj\"], #Options: \"q_proj\" (query), \"k_proj\" (key), \"v_proj\" (value)\n",
    "                            bi = bi,\n",
    "                            pos_heads_dict = pos_heads_dict,\n",
    "                            input_tokens = inputs)) as _:\n",
    "                outputs = llama_model(inputs[\"input_ids\"], output_attentions=True)\n",
    "\n",
    "        for bi in range(inputs[\"labels\"].size(0)):\n",
    "            label = inputs[\"labels\"][bi]\n",
    "            pred = torch.argmax(outputs.logits[bi][inputs[\"last_token_indices\"][bi]])\n",
    "\n",
    "            if label == pred:\n",
    "                correct_count += 1\n",
    "            total_count += 1\n",
    "\n",
    "        del outputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "current_acc = round(correct_count / total_count, 2)\n",
    "print(f\"Task accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a83b98",
   "metadata": {},
   "source": [
    "Input CMAP Results:\n",
    "- Value Fetcher:\n",
    "    - Query: 0.77\n",
    "    - Key: 0.63\n",
    "    - Value: 0.69\n",
    "    - QK: 0.76\n",
    "    - QKV: 0.77\n",
    "- Position Transmitter:\n",
    "    - Query: 0.66\n",
    "    - Key: 0.65\n",
    "    - Value: 0.69\n",
    "    - QK: 0.65\n",
    "    - QKV: 0.67"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bc689b",
   "metadata": {},
   "source": [
    "## Patching Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95c6b029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_weights(inputs=None, output=None, layer=None, bi=None):\n",
    "    inputs = inputs[0]\n",
    "    value_fetcher_curr_layer = [h for l, h in value_fetcher if l == int(layer.split(\".\")[2])]\n",
    "    position_trans_curr_layer = [h for l, h in pos_transmitter if l == int(layer.split(\".\")[2])]\n",
    "\n",
    "    if (\"q_proj\" in layer) and len(value_fetcher_curr_layer) > 0:\n",
    "        llama_w = llama_model.state_dict()[f\"{layer}.weight\"].clone()\n",
    "        goat_w = goat_model.state_dict()[f\"{layer}.weight\"].clone()\n",
    "\n",
    "        llama_w = rearrange(llama_w, \n",
    "                           \"d_model (n_heads d_head) -> d_model n_heads d_head\", \n",
    "                           n_heads=llama_model.config.num_attention_heads,\n",
    "                           )\n",
    "        goat_w = rearrange(goat_w, \n",
    "                           \"d_model (n_heads d_head) -> d_model n_heads d_head\", \n",
    "                           n_heads=goat_model.config.num_attention_heads,\n",
    "                           )\n",
    "\n",
    "#         for head_idx in value_fetcher_curr_layer:\n",
    "        llama_w = goat_w\n",
    "\n",
    "        llama_w = rearrange(llama_w, \n",
    "                           \"d_model n_heads d_head -> d_model (n_heads d_head)\", \n",
    "                           n_heads=llama_model.config.num_attention_heads,\n",
    "                           )\n",
    "\n",
    "        new_output = einsum(\n",
    "            inputs, llama_w, \"batch seq_len hidden_size, d_model hidden_size -> batch seq_len d_model\"\n",
    "        )\n",
    "        output = torch.cat((output[:, :-1], new_output[:, -1].unsqueeze(dim=1)), dim=1)\n",
    "\n",
    "    if (\"o_proj\" in layer) and len(position_trans_curr_layer) > 0:\n",
    "        inputs = rearrange(\n",
    "                inputs,\n",
    "                \"batch seq_len (n_heads d_head) -> batch seq_len n_heads d_head\",\n",
    "                n_heads=llama_model.config.num_attention_heads,\n",
    "            )\n",
    "        \n",
    "        g_cache = rearrange(\n",
    "                goat_cache[bi][layer],\n",
    "                \"batch seq_len (n_heads d_head) -> batch seq_len n_heads d_head\",\n",
    "                n_heads=llama_model.config.num_attention_heads,\n",
    "            )\n",
    "        \n",
    "        for head in position_trans_curr_layer:\n",
    "            inputs[:, -1, head] = g_cache[:, -1, head]\n",
    "        \n",
    "        inputs = rearrange(\n",
    "                inputs,\n",
    "                \"batch seq_len n_heads d_head -> batch seq_len (n_heads d_head)\",\n",
    "                n_heads=llama_model.config.num_attention_heads,\n",
    "            )\n",
    "        w_o = llama_model.state_dict()[f\"{layer}.weight\"]\n",
    "        output = einsum(\n",
    "            inputs, w_o, \"batch seq_len hidden_size, d_model hidden_size -> batch seq_len d_model\"\n",
    "        )\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9aa2800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 1/63 [00:00<00:26,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 2/63 [00:00<00:25,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 3/63 [00:01<00:25,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▋         | 4/63 [00:01<00:24,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 5/63 [00:02<00:24,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|▉         | 6/63 [00:02<00:23,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 7/63 [00:02<00:23,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 8/63 [00:03<00:23,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 9/63 [00:03<00:22,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 10/63 [00:04<00:22,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 11/63 [00:04<00:21,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▉        | 12/63 [00:05<00:21,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██        | 13/63 [00:05<00:21,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 14/63 [00:05<00:20,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 15/63 [00:06<00:20,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 16/63 [00:06<00:19,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 17/63 [00:07<00:19,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▊       | 18/63 [00:07<00:18,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 19/63 [00:08<00:18,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|███▏      | 20/63 [00:08<00:18,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 21/63 [00:08<00:17,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▍      | 22/63 [00:09<00:17,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|███▋      | 23/63 [00:09<00:16,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|███▊      | 24/63 [00:10<00:16,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|███▉      | 25/63 [00:10<00:15,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 41%|████▏     | 26/63 [00:10<00:15,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████▎     | 27/63 [00:11<00:15,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████▍     | 28/63 [00:11<00:14,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 46%|████▌     | 29/63 [00:12<00:14,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|████▊     | 30/63 [00:12<00:13,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 49%|████▉     | 31/63 [00:13<00:13,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 51%|█████     | 32/63 [00:13<00:13,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|█████▏    | 33/63 [00:13<00:12,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 54%|█████▍    | 34/63 [00:14<00:12,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████▌    | 35/63 [00:14<00:11,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|█████▋    | 36/63 [00:15<00:11,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 59%|█████▊    | 37/63 [00:15<00:10,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 38/63 [00:16<00:10,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|██████▏   | 39/63 [00:16<00:10,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|██████▎   | 40/63 [00:16<00:09,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 41/63 [00:17<00:09,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n",
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 42/63 [00:17<00:09,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 68%|██████▊   | 43/63 [00:18<00:08,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|██████▉   | 44/63 [00:18<00:08,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|███████▏  | 45/63 [00:19<00:07,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 73%|███████▎  | 46/63 [00:19<00:07,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▍  | 47/63 [00:19<00:06,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 76%|███████▌  | 48/63 [00:20<00:06,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████▊  | 49/63 [00:20<00:05,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 79%|███████▉  | 50/63 [00:21<00:05,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 81%|████████  | 51/63 [00:21<00:05,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|████████▎ | 52/63 [00:21<00:04,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 84%|████████▍ | 53/63 [00:22<00:04,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 86%|████████▌ | 54/63 [00:22<00:03,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 87%|████████▋ | 55/63 [00:23<00:03,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 89%|████████▉ | 56/63 [00:23<00:02,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 57/63 [00:24<00:02,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 92%|█████████▏| 58/63 [00:24<00:02,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 94%|█████████▎| 59/63 [00:24<00:01,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 60/63 [00:25<00:01,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 97%|█████████▋| 61/63 [00:25<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 98%|█████████▊| 62/63 [00:26<00:00,  2.38it/s]\n",
      "100%|██████████| 63/63 [00:26<00:00,  2.38it/s]\n",
      "63it [00:26,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.14.self_attn.q_proj: llama: 108.36489868164062, fine-tuned: 108.38367462158203\n",
      "model.layers.15.self_attn.q_proj: llama: 108.3883056640625, fine-tuned: 108.40525817871094\n",
      "model.layers.16.self_attn.q_proj: llama: 106.8139419555664, fine-tuned: 106.8269271850586\n",
      "model.layers.17.self_attn.q_proj: llama: 104.55338287353516, fine-tuned: 104.56761932373047\n",
      "model.layers.18.self_attn.q_proj: llama: 103.43733215332031, fine-tuned: 103.45516967773438\n",
      "model.layers.19.self_attn.q_proj: llama: 101.43477630615234, fine-tuned: 101.44762420654297\n",
      "model.layers.20.self_attn.q_proj: llama: 102.77690887451172, fine-tuned: 102.79048156738281\n",
      "model.layers.21.self_attn.q_proj: llama: 99.40530395507812, fine-tuned: 99.41356658935547\n",
      "model.layers.22.self_attn.q_proj: llama: 101.00042724609375, fine-tuned: 101.01142883300781\n",
      "model.layers.23.self_attn.q_proj: llama: 97.8895492553711, fine-tuned: 97.90031433105469\n",
      "model.layers.24.self_attn.q_proj: llama: 97.97964477539062, fine-tuned: 98.0158920288086\n",
      "model.layers.28.self_attn.q_proj: llama: 97.06059265136719, fine-tuned: 97.08554077148438\n",
      "model.layers.29.self_attn.q_proj: llama: 96.15409851074219, fine-tuned: 96.20056915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct_count, total_count = 0, 0\n",
    "llama_model.eval()\n",
    "with torch.no_grad():\n",
    "    for bi, inputs in tqdm(enumerate(tqdm(dataloader))):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(llama_model.device)\n",
    "\n",
    "        with TraceDict(\n",
    "            llama_model,\n",
    "            llama_modules,\n",
    "            retain_input=True,\n",
    "            edit_output=partial(\n",
    "                patch_weights,\n",
    "                bi=bi,\n",
    "            ),\n",
    "        ) as _:\n",
    "            outputs = llama_model(inputs[\"input_ids\"])\n",
    "\n",
    "        for bi in range(inputs[\"labels\"].size(0)):\n",
    "            label = inputs[\"labels\"][bi]\n",
    "            pred = torch.argmax(outputs.logits[bi][inputs[\"last_token_indices\"][bi]])\n",
    "\n",
    "            if label == pred:\n",
    "                correct_count += 1\n",
    "            # else:\n",
    "            #     print(f\"Label: {tokenizer.decode(label)}, Prediction: {tokenizer.decode(pred)}\")\n",
    "            total_count += 1\n",
    "\n",
    "        del outputs\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eabf50b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(correct_count/total_count, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1b1287",
   "metadata": {},
   "source": [
    "## Patching inputs of Value Fetcher Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2b655a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:36,  1.71it/s]\n"
     ]
    }
   ],
   "source": [
    "goat_input_cache = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for bi, inputs in tqdm(enumerate(dataloader)):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(goat_model.device)\n",
    "\n",
    "        with TraceDict(goat_model, llama_modules, retain_input=True) as cache:\n",
    "            _ = goat_model(inputs[\"input_ids\"])\n",
    "\n",
    "        for _, llama_layer in zip(goat_modules, llama_modules):\n",
    "            if \"o_proj\" not in llama_layer:\n",
    "                if bi in goat_input_cache:\n",
    "                    goat_input_cache[bi][llama_layer] = cache[llama_layer].input.cpu()\n",
    "                else:\n",
    "                    goat_input_cache[bi] = {}\n",
    "                    goat_input_cache[bi][llama_layer] = cache[llama_layer].input.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "88aebfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_inputs(inputs=None, output=None, layer=None, bi=None):\n",
    "    inp = inputs[0]\n",
    "    value_fetcher_curr_layer = [h for l, h in value_fetcher if l == int(layer.split(\".\")[2])]\n",
    "    position_trans_curr_layer = [h for l, h in pos_transmitter if l == int(layer.split(\".\")[2])]\n",
    "\n",
    "    if (\"k_proj\" in layer) and len(value_fetcher_curr_layer) > 0:\n",
    "        # Patching inputs and weights of value fetcher heads from fine-tuned to llama\n",
    "\n",
    "        goat_inp = goat_input_cache[bi][layer]\n",
    "\n",
    "        llama_w = llama_model.state_dict()[f\"{layer}.weight\"].clone()\n",
    "        llama_w = rearrange(llama_w, \n",
    "                           \"(n_heads d_head) d_model -> n_heads d_head d_model\", \n",
    "                           n_heads=goat_model.config.num_attention_heads)\n",
    "        \n",
    "        goat_w = goat_model.state_dict()[f\"{layer}.weight\"].clone()\n",
    "        goat_w = rearrange(goat_w, \n",
    "                           \"(n_heads d_head) d_model -> n_heads d_head d_model\", \n",
    "                           n_heads=goat_model.config.num_attention_heads)\n",
    "\n",
    "        output = rearrange(output, \n",
    "                   \"batch seq_len (n_heads d_head) -> batch seq_len n_heads d_head\", \n",
    "                   n_heads=goat_model.config.num_attention_heads)\n",
    "\n",
    "        for head_idx in value_fetcher_curr_layer:\n",
    "            res = einsum(goat_inp.cuda(),\n",
    "                          llama_w[head_idx, :],\n",
    "                          \"batch seq_len hidden_size, d_head hidden_size -> batch seq_len d_head\")\n",
    "            output[:, -1, head_idx] = res[:, -1]\n",
    "\n",
    "        output = rearrange(output, \n",
    "                       \"batch seq_len n_heads d_head -> batch seq_len (n_heads d_head)\", \n",
    "                       n_heads=llama_model.config.num_attention_heads)\n",
    "\n",
    "#     if (\"o_proj\" in layer) and len(position_trans_curr_layer) > 0:\n",
    "#         inp = rearrange(\n",
    "#                 inp,\n",
    "#                 \"batch seq_len (n_heads d_head) -> batch seq_len n_heads d_head\",\n",
    "#                 n_heads=llama_model.config.num_attention_heads)\n",
    "        \n",
    "#         g_cache = rearrange(\n",
    "#                 goat_cache[bi][layer],\n",
    "#                 \"batch seq_len (n_heads d_head) -> batch seq_len n_heads d_head\",\n",
    "#                 n_heads=llama_model.config.num_attention_heads)\n",
    "        \n",
    "#         for head in position_trans_curr_layer:\n",
    "#             inp[:, -1, head] = g_cache[:, -1, head]\n",
    "        \n",
    "#         inp = rearrange(\n",
    "#                 inp,\n",
    "#                 \"batch seq_len n_heads d_head -> batch seq_len (n_heads d_head)\",\n",
    "#                 n_heads=llama_model.config.num_attention_heads)\n",
    "#         w_o = llama_model.state_dict()[f\"{layer}.weight\"]\n",
    "#         output = einsum(\n",
    "#             inp, w_o, \"batch seq_len hidden_size, d_model hidden_size -> batch seq_len d_model\")\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aecc97f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/63 [00:00<00:26,  2.31it/s]\n",
      "  3%|▎         | 2/63 [00:00<00:26,  2.31it/s]\n",
      "  5%|▍         | 3/63 [00:01<00:25,  2.31it/s]\n",
      "  6%|▋         | 4/63 [00:01<00:25,  2.32it/s]\n",
      "  8%|▊         | 5/63 [00:02<00:24,  2.32it/s]\n",
      " 10%|▉         | 6/63 [00:02<00:24,  2.33it/s]\n",
      " 11%|█         | 7/63 [00:03<00:24,  2.33it/s]\n",
      " 13%|█▎        | 8/63 [00:03<00:23,  2.33it/s]\n",
      " 14%|█▍        | 9/63 [00:03<00:23,  2.34it/s]\n",
      " 16%|█▌        | 10/63 [00:04<00:22,  2.34it/s]\n",
      " 17%|█▋        | 11/63 [00:04<00:22,  2.34it/s]\n",
      " 19%|█▉        | 12/63 [00:05<00:21,  2.34it/s]\n",
      " 21%|██        | 13/63 [00:05<00:21,  2.34it/s]\n",
      " 22%|██▏       | 14/63 [00:06<00:20,  2.34it/s]\n",
      " 24%|██▍       | 15/63 [00:06<00:20,  2.33it/s]\n",
      " 25%|██▌       | 16/63 [00:06<00:20,  2.33it/s]\n",
      " 27%|██▋       | 17/63 [00:07<00:19,  2.33it/s]\n",
      " 29%|██▊       | 18/63 [00:07<00:19,  2.33it/s]\n",
      " 30%|███       | 19/63 [00:08<00:18,  2.33it/s]\n",
      " 32%|███▏      | 20/63 [00:08<00:18,  2.33it/s]\n",
      " 33%|███▎      | 21/63 [00:09<00:18,  2.33it/s]\n",
      " 35%|███▍      | 22/63 [00:09<00:17,  2.33it/s]\n",
      " 37%|███▋      | 23/63 [00:09<00:17,  2.33it/s]\n",
      " 38%|███▊      | 24/63 [00:10<00:16,  2.33it/s]\n",
      " 40%|███▉      | 25/63 [00:10<00:16,  2.33it/s]\n",
      " 41%|████▏     | 26/63 [00:11<00:15,  2.33it/s]\n",
      " 43%|████▎     | 27/63 [00:11<00:15,  2.33it/s]\n",
      " 44%|████▍     | 28/63 [00:12<00:14,  2.33it/s]\n",
      " 46%|████▌     | 29/63 [00:12<00:14,  2.34it/s]\n",
      " 48%|████▊     | 30/63 [00:12<00:14,  2.34it/s]\n",
      " 49%|████▉     | 31/63 [00:13<00:13,  2.34it/s]\n",
      " 51%|█████     | 32/63 [00:13<00:13,  2.34it/s]\n",
      " 52%|█████▏    | 33/63 [00:14<00:12,  2.34it/s]\n",
      " 54%|█████▍    | 34/63 [00:14<00:12,  2.34it/s]\n",
      " 56%|█████▌    | 35/63 [00:15<00:11,  2.34it/s]\n",
      " 57%|█████▋    | 36/63 [00:15<00:11,  2.34it/s]\n",
      " 59%|█████▊    | 37/63 [00:16<00:12,  2.12it/s]\n",
      " 60%|██████    | 38/63 [00:16<00:11,  2.18it/s]\n",
      " 62%|██████▏   | 39/63 [00:16<00:10,  2.22it/s]\n",
      " 63%|██████▎   | 40/63 [00:17<00:10,  2.25it/s]\n",
      " 65%|██████▌   | 41/63 [00:17<00:09,  2.28it/s]\n",
      " 67%|██████▋   | 42/63 [00:18<00:09,  2.29it/s]\n",
      " 68%|██████▊   | 43/63 [00:18<00:08,  2.31it/s]\n",
      " 70%|██████▉   | 44/63 [00:19<00:08,  2.32it/s]\n",
      " 71%|███████▏  | 45/63 [00:19<00:07,  2.32it/s]\n",
      " 73%|███████▎  | 46/63 [00:19<00:07,  2.31it/s]\n",
      " 75%|███████▍  | 47/63 [00:20<00:06,  2.31it/s]\n",
      " 76%|███████▌  | 48/63 [00:20<00:06,  2.32it/s]\n",
      " 78%|███████▊  | 49/63 [00:21<00:06,  2.32it/s]\n",
      " 79%|███████▉  | 50/63 [00:21<00:05,  2.32it/s]\n",
      " 81%|████████  | 51/63 [00:22<00:05,  2.31it/s]\n",
      " 83%|████████▎ | 52/63 [00:22<00:04,  2.31it/s]\n",
      " 84%|████████▍ | 53/63 [00:22<00:04,  2.31it/s]\n",
      " 86%|████████▌ | 54/63 [00:23<00:03,  2.32it/s]\n",
      " 87%|████████▋ | 55/63 [00:23<00:03,  2.32it/s]\n",
      " 89%|████████▉ | 56/63 [00:24<00:03,  2.32it/s]\n",
      " 90%|█████████ | 57/63 [00:24<00:02,  2.32it/s]\n",
      " 92%|█████████▏| 58/63 [00:25<00:02,  2.32it/s]\n",
      " 94%|█████████▎| 59/63 [00:25<00:01,  2.32it/s]\n",
      " 95%|█████████▌| 60/63 [00:25<00:01,  2.33it/s]\n",
      " 97%|█████████▋| 61/63 [00:26<00:00,  2.32it/s]\n",
      " 98%|█████████▊| 62/63 [00:26<00:00,  2.33it/s]\n",
      "100%|██████████| 63/63 [00:27<00:00,  2.33it/s]\n",
      "63it [00:27,  2.33it/s]\n"
     ]
    }
   ],
   "source": [
    "correct_count, total_count = 0, 0\n",
    "with torch.no_grad():\n",
    "    for bi, inputs in tqdm(enumerate(tqdm(dataloader))):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(llama_model.device)\n",
    "\n",
    "        with TraceDict(\n",
    "            llama_model,\n",
    "            llama_modules,\n",
    "            retain_input=True,\n",
    "            edit_output=partial(\n",
    "                patch_inputs,\n",
    "                bi=bi,\n",
    "            ),\n",
    "        ) as _:\n",
    "            outputs = llama_model(inputs[\"input_ids\"])\n",
    "\n",
    "        for bi in range(inputs[\"labels\"].size(0)):\n",
    "            label = inputs[\"labels\"][bi]\n",
    "            pred = torch.argmax(outputs.logits[bi][inputs[\"last_token_indices\"][bi]])\n",
    "\n",
    "            if label == pred:\n",
    "                correct_count += 1\n",
    "            # else:\n",
    "            #     print(f\"Label: {tokenizer.decode(label)}, Prediction: {tokenizer.decode(pred)}\")\n",
    "            total_count += 1\n",
    "\n",
    "        del outputs\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b141b61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(correct_count/total_count, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2510d342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.14.self_attn.k_proj, Llama weight: 109.2076416015625, Fine-tuned weight: 109.2258071899414\n",
      "Layer: model.layers.14.self_attn.k_proj, Distance: 3.194016456604004\n",
      "\n",
      "Layer: model.layers.14.self_attn.q_proj, Llama weight: 108.36489868164062, Fine-tuned weight: 108.38367462158203\n",
      "Layer: model.layers.14.self_attn.q_proj, Distance: 3.2767512798309326\n",
      "\n",
      "Layer: model.layers.14.self_attn.v_proj, Llama weight: 77.7557373046875, Fine-tuned weight: 77.76526641845703\n",
      "Layer: model.layers.14.self_attn.v_proj, Distance: 2.292689085006714\n",
      "\n",
      "Layer: model.layers.14.self_attn.o_proj, Llama weight: 77.85401916503906, Fine-tuned weight: 77.86835479736328\n",
      "Layer: model.layers.14.self_attn.o_proj, Distance: 2.7456164360046387\n",
      "\n",
      "Layer: model.layers.15.self_attn.k_proj, Llama weight: 110.20281982421875, Fine-tuned weight: 110.21894073486328\n",
      "Layer: model.layers.15.self_attn.k_proj, Distance: 3.171581983566284\n",
      "\n",
      "Layer: model.layers.15.self_attn.q_proj, Llama weight: 108.3883056640625, Fine-tuned weight: 108.40525817871094\n",
      "Layer: model.layers.15.self_attn.q_proj, Distance: 3.219693899154663\n",
      "\n",
      "Layer: model.layers.15.self_attn.v_proj, Llama weight: 78.00812530517578, Fine-tuned weight: 78.01932525634766\n",
      "Layer: model.layers.15.self_attn.v_proj, Distance: 2.4315185546875\n",
      "\n",
      "Layer: model.layers.15.self_attn.o_proj, Llama weight: 78.0924301147461, Fine-tuned weight: 78.10601806640625\n",
      "Layer: model.layers.15.self_attn.o_proj, Distance: 2.7020890712738037\n",
      "\n",
      "Layer: model.layers.16.self_attn.k_proj, Llama weight: 109.59322357177734, Fine-tuned weight: 109.60608673095703\n",
      "Layer: model.layers.16.self_attn.k_proj, Distance: 2.9003829956054688\n",
      "\n",
      "Layer: model.layers.16.self_attn.q_proj, Llama weight: 106.8139419555664, Fine-tuned weight: 106.8269271850586\n",
      "Layer: model.layers.16.self_attn.q_proj, Distance: 2.9348833560943604\n",
      "\n",
      "Layer: model.layers.16.self_attn.v_proj, Llama weight: 82.99272918701172, Fine-tuned weight: 83.0025863647461\n",
      "Layer: model.layers.16.self_attn.v_proj, Distance: 2.40889573097229\n",
      "\n",
      "Layer: model.layers.16.self_attn.o_proj, Llama weight: 82.77273559570312, Fine-tuned weight: 82.78438568115234\n",
      "Layer: model.layers.16.self_attn.o_proj, Distance: 2.575176477432251\n",
      "\n",
      "Layer: model.layers.17.self_attn.k_proj, Llama weight: 106.67488861083984, Fine-tuned weight: 106.68788146972656\n",
      "Layer: model.layers.17.self_attn.k_proj, Distance: 2.9029452800750732\n",
      "\n",
      "Layer: model.layers.17.self_attn.q_proj, Llama weight: 104.55338287353516, Fine-tuned weight: 104.56761932373047\n",
      "Layer: model.layers.17.self_attn.q_proj, Distance: 2.9746556282043457\n",
      "\n",
      "Layer: model.layers.17.self_attn.v_proj, Llama weight: 83.5419692993164, Fine-tuned weight: 83.55260467529297\n",
      "Layer: model.layers.17.self_attn.v_proj, Distance: 2.536048173904419\n",
      "\n",
      "Layer: model.layers.17.self_attn.o_proj, Llama weight: 83.80196380615234, Fine-tuned weight: 83.81587219238281\n",
      "Layer: model.layers.17.self_attn.o_proj, Distance: 2.794328451156616\n",
      "\n",
      "Layer: model.layers.18.self_attn.k_proj, Llama weight: 104.67532348632812, Fine-tuned weight: 104.69341278076172\n",
      "Layer: model.layers.18.self_attn.k_proj, Distance: 3.175630807876587\n",
      "\n",
      "Layer: model.layers.18.self_attn.q_proj, Llama weight: 103.43733215332031, Fine-tuned weight: 103.45516967773438\n",
      "Layer: model.layers.18.self_attn.q_proj, Distance: 3.1718051433563232\n",
      "\n",
      "Layer: model.layers.18.self_attn.v_proj, Llama weight: 83.36076354980469, Fine-tuned weight: 83.37071990966797\n",
      "Layer: model.layers.18.self_attn.v_proj, Distance: 2.3829028606414795\n",
      "\n",
      "Layer: model.layers.18.self_attn.o_proj, Llama weight: 83.5428695678711, Fine-tuned weight: 83.5533218383789\n",
      "Layer: model.layers.18.self_attn.o_proj, Distance: 2.4544758796691895\n",
      "\n",
      "Layer: model.layers.19.self_attn.k_proj, Llama weight: 102.70852661132812, Fine-tuned weight: 102.72016143798828\n",
      "Layer: model.layers.19.self_attn.k_proj, Distance: 2.7618746757507324\n",
      "\n",
      "Layer: model.layers.19.self_attn.q_proj, Llama weight: 101.43477630615234, Fine-tuned weight: 101.44762420654297\n",
      "Layer: model.layers.19.self_attn.q_proj, Distance: 2.9011294841766357\n",
      "\n",
      "Layer: model.layers.19.self_attn.v_proj, Llama weight: 87.40119934082031, Fine-tuned weight: 87.4087142944336\n",
      "Layer: model.layers.19.self_attn.v_proj, Distance: 2.285794734954834\n",
      "\n",
      "Layer: model.layers.19.self_attn.o_proj, Llama weight: 87.06805419921875, Fine-tuned weight: 87.07781219482422\n",
      "Layer: model.layers.19.self_attn.o_proj, Distance: 2.557598114013672\n",
      "\n",
      "Layer: model.layers.20.self_attn.k_proj, Llama weight: 104.3537826538086, Fine-tuned weight: 104.36691284179688\n",
      "Layer: model.layers.20.self_attn.k_proj, Distance: 3.015244960784912\n",
      "\n",
      "Layer: model.layers.20.self_attn.q_proj, Llama weight: 102.77690887451172, Fine-tuned weight: 102.79048156738281\n",
      "Layer: model.layers.20.self_attn.q_proj, Distance: 3.0757291316986084\n",
      "\n",
      "Layer: model.layers.20.self_attn.v_proj, Llama weight: 90.20407104492188, Fine-tuned weight: 90.21672821044922\n",
      "Layer: model.layers.20.self_attn.v_proj, Distance: 2.8210277557373047\n",
      "\n",
      "Layer: model.layers.20.self_attn.o_proj, Llama weight: 89.24221801757812, Fine-tuned weight: 89.2577133178711\n",
      "Layer: model.layers.20.self_attn.o_proj, Distance: 3.0466015338897705\n",
      "\n",
      "Layer: model.layers.21.self_attn.k_proj, Llama weight: 100.40249633789062, Fine-tuned weight: 100.40985107421875\n",
      "Layer: model.layers.21.self_attn.k_proj, Distance: 2.2769036293029785\n",
      "\n",
      "Layer: model.layers.21.self_attn.q_proj, Llama weight: 99.40530395507812, Fine-tuned weight: 99.41356658935547\n",
      "Layer: model.layers.21.self_attn.q_proj, Distance: 2.3410143852233887\n",
      "\n",
      "Layer: model.layers.21.self_attn.v_proj, Llama weight: 90.8724136352539, Fine-tuned weight: 90.87934112548828\n",
      "Layer: model.layers.21.self_attn.v_proj, Distance: 2.133946180343628\n",
      "\n",
      "Layer: model.layers.21.self_attn.o_proj, Llama weight: 89.91780090332031, Fine-tuned weight: 89.92596435546875\n",
      "Layer: model.layers.21.self_attn.o_proj, Distance: 2.325704574584961\n",
      "\n",
      "Layer: model.layers.22.self_attn.k_proj, Llama weight: 102.0159912109375, Fine-tuned weight: 102.0255126953125\n",
      "Layer: model.layers.22.self_attn.k_proj, Distance: 2.823323965072632\n",
      "\n",
      "Layer: model.layers.22.self_attn.q_proj, Llama weight: 101.00042724609375, Fine-tuned weight: 101.01142883300781\n",
      "Layer: model.layers.22.self_attn.q_proj, Distance: 2.964385986328125\n",
      "\n",
      "Layer: model.layers.22.self_attn.v_proj, Llama weight: 90.23123168945312, Fine-tuned weight: 90.24358367919922\n",
      "Layer: model.layers.22.self_attn.v_proj, Distance: 2.8333332538604736\n",
      "\n",
      "Layer: model.layers.22.self_attn.o_proj, Llama weight: 90.159912109375, Fine-tuned weight: 90.17521667480469\n",
      "Layer: model.layers.22.self_attn.o_proj, Distance: 3.069056510925293\n",
      "\n",
      "Layer: model.layers.23.self_attn.k_proj, Llama weight: 98.2370834350586, Fine-tuned weight: 98.24718475341797\n",
      "Layer: model.layers.23.self_attn.k_proj, Distance: 2.5737662315368652\n",
      "\n",
      "Layer: model.layers.23.self_attn.q_proj, Llama weight: 97.8895492553711, Fine-tuned weight: 97.90031433105469\n",
      "Layer: model.layers.23.self_attn.q_proj, Distance: 2.6578941345214844\n",
      "\n",
      "Layer: model.layers.23.self_attn.v_proj, Llama weight: 93.85975646972656, Fine-tuned weight: 93.86788940429688\n",
      "Layer: model.layers.23.self_attn.v_proj, Distance: 2.4020490646362305\n",
      "\n",
      "Layer: model.layers.23.self_attn.o_proj, Llama weight: 92.6123275756836, Fine-tuned weight: 92.62284088134766\n",
      "Layer: model.layers.23.self_attn.o_proj, Distance: 2.6579155921936035\n",
      "\n",
      "Layer: model.layers.24.self_attn.k_proj, Llama weight: 98.64533233642578, Fine-tuned weight: 98.68011474609375\n",
      "Layer: model.layers.24.self_attn.k_proj, Distance: 4.0872344970703125\n",
      "\n",
      "Layer: model.layers.24.self_attn.q_proj, Llama weight: 97.97964477539062, Fine-tuned weight: 98.0158920288086\n",
      "Layer: model.layers.24.self_attn.q_proj, Distance: 4.201998233795166\n",
      "\n",
      "Layer: model.layers.24.self_attn.v_proj, Llama weight: 95.02095031738281, Fine-tuned weight: 95.04651641845703\n",
      "Layer: model.layers.24.self_attn.v_proj, Distance: 3.814260482788086\n",
      "\n",
      "Layer: model.layers.24.self_attn.o_proj, Llama weight: 93.77462005615234, Fine-tuned weight: 93.80659484863281\n",
      "Layer: model.layers.24.self_attn.o_proj, Distance: 4.183737277984619\n",
      "\n",
      "Layer: model.layers.28.self_attn.k_proj, Llama weight: 97.66861724853516, Fine-tuned weight: 97.69147491455078\n",
      "Layer: model.layers.28.self_attn.k_proj, Distance: 3.6112866401672363\n",
      "\n",
      "Layer: model.layers.28.self_attn.q_proj, Llama weight: 97.06059265136719, Fine-tuned weight: 97.08554077148438\n",
      "Layer: model.layers.28.self_attn.q_proj, Distance: 3.6904122829437256\n",
      "\n",
      "Layer: model.layers.28.self_attn.v_proj, Llama weight: 100.43128204345703, Fine-tuned weight: 100.44557189941406\n",
      "Layer: model.layers.28.self_attn.v_proj, Distance: 3.07395601272583\n",
      "\n",
      "Layer: model.layers.28.self_attn.o_proj, Llama weight: 100.70840454101562, Fine-tuned weight: 100.72613525390625\n",
      "Layer: model.layers.28.self_attn.o_proj, Distance: 3.4285552501678467\n",
      "\n",
      "Layer: model.layers.29.self_attn.k_proj, Llama weight: 97.12875366210938, Fine-tuned weight: 97.17386627197266\n",
      "Layer: model.layers.29.self_attn.k_proj, Distance: 4.60258674621582\n",
      "\n",
      "Layer: model.layers.29.self_attn.q_proj, Llama weight: 96.15409851074219, Fine-tuned weight: 96.20056915283203\n",
      "Layer: model.layers.29.self_attn.q_proj, Distance: 4.699370384216309\n",
      "\n",
      "Layer: model.layers.29.self_attn.v_proj, Llama weight: 103.44515991210938, Fine-tuned weight: 103.48084259033203\n",
      "Layer: model.layers.29.self_attn.v_proj, Distance: 4.401933193206787\n",
      "\n",
      "Layer: model.layers.29.self_attn.o_proj, Llama weight: 103.70858001708984, Fine-tuned weight: 103.74691009521484\n",
      "Layer: model.layers.29.self_attn.o_proj, Distance: 4.589578628540039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for layer in llama_modules:\n",
    "    llama_w = llama_model.state_dict()[f\"{layer}.weight\"].clone()\n",
    "    goat_w = goat_model.state_dict()[f\"{layer}.weight\"].clone()\n",
    "    value_fetcher_curr_layer = [h for l, h in value_fetcher if l == int(layer.split(\".\")[2])]\n",
    "\n",
    "    if len(value_fetcher_curr_layer) > 0:\n",
    "        print(f\"Layer: {layer}, Llama weight: {llama_w.norm().item()}, Fine-tuned weight: {goat_w.norm().item()}\")\n",
    "        print(f\"Layer: {layer}, Distance: {torch.dist(llama_w, goat_w)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b4c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
